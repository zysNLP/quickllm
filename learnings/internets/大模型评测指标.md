大模型常用评测指标，常见的有Pass@1、EM、LC-winrate/winrate、CSL等，以下是关于这几个指标的简要介绍
1. Pass@1
定义：

在代码生成等任务中，Pass@1 表示模型在第一次尝试时就能正确生成目标答案的比例。
通常用于衡量代码自动补全、编程题解答等场景。
举例：

如果有100道编程题，模型第一次输出就正确解决了80道，则 Pass@1 = 80%。
2. EM（Exact Match）
定义：

精确匹配率。指模型输出与标准答案完全一致的样本比例。
常用于问答、文本生成等需要严格比对结果的任务。
举例：

给定10个问题，有7个回答和参考答案一字不差，则 EM = 70%。
3. LC-winrate（Leaderboard Comparison Win Rate）
定义：

一种基于排行榜或标杆系统的人类偏好胜率指标，用于比较两个或多个大语言模型在同一组测试集上的表现优劣。
测试者会判断哪一个模型给出的回答更好，“winrate”即为被认为更好的概率/百分比。
区别说明：

“LC”通常指某些公开榜单如“LeaderBoard”的缩写，但具体含义可能随不同社区而异，一般可理解为“大规模人类评价下获胜概率”。
4. winrate
定义：

胜率。通常在人类评价或者A/B测试中使用，即让人工评审员同时看到两个（或多个）模型对同一道题目的回答，然后选择哪个更好，统计每个模型被选中的频次占总次数的比例。
应用场景：

用于主观性较强的问题，如开放式问答、多轮对话、创意写作等领域，比自动化分数更加贴近真实用户体验。
5. CSL（Chinese Super-Large Language Model Evaluation Benchmark）
定义：

中文超大规模语言模型评测基准，是专门针对中文语境下的大型语言模型设计的一套综合性测试体系。
内容涵盖：

包括知识问答、推理能力、数学运算、多轮对话、阅读理解等多方面子任务，通过这些子任务来全面考察中文大语言模型能力水平。
总结表格
指标	全称/含义	应用场景
Pass@1	首次通过率	编码/代码生成
EM	精确匹配	问答/信息抽取
LC-winrate/winrate	人工胜率	主观质量比较
CSL	中文大型评测基准	综合能力，多领域
————————————————

                            版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。
                        
原文链接：https://blog.csdn.net/airstudy/article/details/147855696