{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.996381618622603,
  "eval_steps": 500,
  "global_step": 20720,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04824508503196237,
      "grad_norm": 0.9695440530776978,
      "learning_rate": 0.00019998850571589113,
      "loss": 6.6873,
      "step": 100
    },
    {
      "epoch": 0.09649017006392474,
      "grad_norm": 1.3106155395507812,
      "learning_rate": 0.00019995402550593592,
      "loss": 5.0894,
      "step": 200
    },
    {
      "epoch": 0.1447352550958871,
      "grad_norm": 1.2277331352233887,
      "learning_rate": 0.0001998965672966409,
      "loss": 4.4562,
      "step": 300
    },
    {
      "epoch": 0.19298034012784948,
      "grad_norm": 1.3889118432998657,
      "learning_rate": 0.00019981614429682575,
      "loss": 4.1175,
      "step": 400
    },
    {
      "epoch": 0.24122542515981185,
      "grad_norm": 1.7326412200927734,
      "learning_rate": 0.0001997127749945866,
      "loss": 3.8955,
      "step": 500
    },
    {
      "epoch": 0.2894705101917742,
      "grad_norm": 1.4078567028045654,
      "learning_rate": 0.00019958648315304608,
      "loss": 3.7337,
      "step": 600
    },
    {
      "epoch": 0.33771559522373656,
      "grad_norm": 1.2864357233047485,
      "learning_rate": 0.00019943729780489027,
      "loss": 3.6019,
      "step": 700
    },
    {
      "epoch": 0.38596068025569896,
      "grad_norm": 1.1232216358184814,
      "learning_rate": 0.00019926525324569472,
      "loss": 3.4877,
      "step": 800
    },
    {
      "epoch": 0.4342057652876613,
      "grad_norm": 1.4618659019470215,
      "learning_rate": 0.0001990703890260403,
      "loss": 3.3841,
      "step": 900
    },
    {
      "epoch": 0.4824508503196237,
      "grad_norm": 1.160987138748169,
      "learning_rate": 0.00019885274994242108,
      "loss": 3.2938,
      "step": 1000
    },
    {
      "epoch": 0.5306959353515861,
      "grad_norm": 1.281429648399353,
      "learning_rate": 0.00019861238602694625,
      "loss": 3.2202,
      "step": 1100
    },
    {
      "epoch": 0.5789410203835484,
      "grad_norm": 1.2475343942642212,
      "learning_rate": 0.0001983493525358385,
      "loss": 3.1604,
      "step": 1200
    },
    {
      "epoch": 0.6271861054155108,
      "grad_norm": 1.1051727533340454,
      "learning_rate": 0.00019806370993673137,
      "loss": 3.1093,
      "step": 1300
    },
    {
      "epoch": 0.6754311904474731,
      "grad_norm": 1.1916652917861938,
      "learning_rate": 0.00019775552389476864,
      "loss": 3.0699,
      "step": 1400
    },
    {
      "epoch": 0.7236762754794356,
      "grad_norm": 1.2147717475891113,
      "learning_rate": 0.00019742486525750873,
      "loss": 3.0358,
      "step": 1500
    },
    {
      "epoch": 0.7719213605113979,
      "grad_norm": 1.0860424041748047,
      "learning_rate": 0.00019707181003863808,
      "loss": 3.0022,
      "step": 1600
    },
    {
      "epoch": 0.8201664455433603,
      "grad_norm": 1.1232692003250122,
      "learning_rate": 0.00019669643940049657,
      "loss": 2.9747,
      "step": 1700
    },
    {
      "epoch": 0.8684115305753226,
      "grad_norm": 0.9894734621047974,
      "learning_rate": 0.00019629883963541932,
      "loss": 2.9484,
      "step": 1800
    },
    {
      "epoch": 0.916656615607285,
      "grad_norm": 0.960679292678833,
      "learning_rate": 0.00019587910214589966,
      "loss": 2.9255,
      "step": 1900
    },
    {
      "epoch": 0.9649017006392474,
      "grad_norm": 1.057227611541748,
      "learning_rate": 0.00019543732342357662,
      "loss": 2.9029,
      "step": 2000
    },
    {
      "epoch": 1.0131467856712097,
      "grad_norm": 0.9177830219268799,
      "learning_rate": 0.0001949736050270532,
      "loss": 2.8834,
      "step": 2100
    },
    {
      "epoch": 1.0613918707031722,
      "grad_norm": 0.839387834072113,
      "learning_rate": 0.00019448805355854932,
      "loss": 2.8651,
      "step": 2200
    },
    {
      "epoch": 1.1096369557351344,
      "grad_norm": 0.8573579788208008,
      "learning_rate": 0.00019398078063939553,
      "loss": 2.8485,
      "step": 2300
    },
    {
      "epoch": 1.1578820407670969,
      "grad_norm": 0.879298985004425,
      "learning_rate": 0.00019345190288437293,
      "loss": 2.8344,
      "step": 2400
    },
    {
      "epoch": 1.2061271257990591,
      "grad_norm": 0.8788741827011108,
      "learning_rate": 0.00019290154187490493,
      "loss": 2.8197,
      "step": 2500
    },
    {
      "epoch": 1.2543722108310216,
      "grad_norm": 0.7006978392601013,
      "learning_rate": 0.0001923298241311078,
      "loss": 2.8085,
      "step": 2600
    },
    {
      "epoch": 1.302617295862984,
      "grad_norm": 0.7318152785301208,
      "learning_rate": 0.00019173688108270495,
      "loss": 2.7953,
      "step": 2700
    },
    {
      "epoch": 1.3508623808949463,
      "grad_norm": 0.8601279258728027,
      "learning_rate": 0.0001911228490388136,
      "loss": 2.7848,
      "step": 2800
    },
    {
      "epoch": 1.3991074659269087,
      "grad_norm": 0.9793972373008728,
      "learning_rate": 0.00019048786915660902,
      "loss": 2.7745,
      "step": 2900
    },
    {
      "epoch": 1.447352550958871,
      "grad_norm": 0.6884327530860901,
      "learning_rate": 0.00018983208740887465,
      "loss": 2.7635,
      "step": 3000
    },
    {
      "epoch": 1.4955976359908334,
      "grad_norm": 0.8942821025848389,
      "learning_rate": 0.00018915565455044484,
      "loss": 2.7535,
      "step": 3100
    },
    {
      "epoch": 1.5438427210227958,
      "grad_norm": 0.8267655372619629,
      "learning_rate": 0.00018845872608354877,
      "loss": 2.7457,
      "step": 3200
    },
    {
      "epoch": 1.5920878060547583,
      "grad_norm": 0.7489218711853027,
      "learning_rate": 0.00018774146222206247,
      "loss": 2.7368,
      "step": 3300
    },
    {
      "epoch": 1.6403328910867205,
      "grad_norm": 0.6232801675796509,
      "learning_rate": 0.00018700402785467804,
      "loss": 2.7272,
      "step": 3400
    },
    {
      "epoch": 1.6885779761186828,
      "grad_norm": 0.8020843267440796,
      "learning_rate": 0.00018624659250699805,
      "loss": 2.7206,
      "step": 3500
    },
    {
      "epoch": 1.7368230611506452,
      "grad_norm": 0.8353101015090942,
      "learning_rate": 0.00018546933030256417,
      "loss": 2.7124,
      "step": 3600
    },
    {
      "epoch": 1.7850681461826077,
      "grad_norm": 0.8912534713745117,
      "learning_rate": 0.00018467241992282843,
      "loss": 2.704,
      "step": 3700
    },
    {
      "epoch": 1.8333132312145701,
      "grad_norm": 0.8063448071479797,
      "learning_rate": 0.00018385604456607716,
      "loss": 2.7008,
      "step": 3800
    },
    {
      "epoch": 1.8815583162465324,
      "grad_norm": 0.6187765598297119,
      "learning_rate": 0.0001830203919053161,
      "loss": 2.6934,
      "step": 3900
    },
    {
      "epoch": 1.9298034012784946,
      "grad_norm": 0.9673050045967102,
      "learning_rate": 0.0001821656540451273,
      "loss": 2.6864,
      "step": 4000
    },
    {
      "epoch": 1.978048486310457,
      "grad_norm": 1.0125843286514282,
      "learning_rate": 0.00018129202747750679,
      "loss": 2.6814,
      "step": 4100
    },
    {
      "epoch": 2.0262935713424195,
      "grad_norm": 0.7559195160865784,
      "learning_rate": 0.00018039971303669407,
      "loss": 2.6726,
      "step": 4200
    },
    {
      "epoch": 2.074538656374382,
      "grad_norm": 0.6671071648597717,
      "learning_rate": 0.00017948891585300306,
      "loss": 2.6662,
      "step": 4300
    },
    {
      "epoch": 2.1227837414063444,
      "grad_norm": 0.912709653377533,
      "learning_rate": 0.00017855984530566564,
      "loss": 2.6614,
      "step": 4400
    },
    {
      "epoch": 2.1710288264383064,
      "grad_norm": 0.7040593028068542,
      "learning_rate": 0.00017761271497469838,
      "loss": 2.6565,
      "step": 4500
    },
    {
      "epoch": 2.219273911470269,
      "grad_norm": 0.7414091229438782,
      "learning_rate": 0.00017664774259180358,
      "loss": 2.6517,
      "step": 4600
    },
    {
      "epoch": 2.2675189965022313,
      "grad_norm": 0.7797924876213074,
      "learning_rate": 0.0001756651499903157,
      "loss": 2.6467,
      "step": 4700
    },
    {
      "epoch": 2.3157640815341938,
      "grad_norm": 0.6885104179382324,
      "learning_rate": 0.00017466516305420524,
      "loss": 2.6417,
      "step": 4800
    },
    {
      "epoch": 2.3640091665661562,
      "grad_norm": 0.5571252703666687,
      "learning_rate": 0.00017364801166615124,
      "loss": 2.6377,
      "step": 4900
    },
    {
      "epoch": 2.4122542515981182,
      "grad_norm": 0.8307214975357056,
      "learning_rate": 0.00017261392965469433,
      "loss": 2.6348,
      "step": 5000
    },
    {
      "epoch": 2.4604993366300807,
      "grad_norm": 0.6373889446258545,
      "learning_rate": 0.00017156315474048321,
      "loss": 2.6303,
      "step": 5100
    },
    {
      "epoch": 2.508744421662043,
      "grad_norm": 0.6675624251365662,
      "learning_rate": 0.00017049592848162584,
      "loss": 2.6273,
      "step": 5200
    },
    {
      "epoch": 2.5569895066940056,
      "grad_norm": 0.6191921830177307,
      "learning_rate": 0.00016941249621815874,
      "loss": 2.622,
      "step": 5300
    },
    {
      "epoch": 2.605234591725968,
      "grad_norm": 0.7921512126922607,
      "learning_rate": 0.0001683131070156469,
      "loss": 2.6198,
      "step": 5400
    },
    {
      "epoch": 2.6534796767579305,
      "grad_norm": 0.7763290405273438,
      "learning_rate": 0.00016719801360792712,
      "loss": 2.6144,
      "step": 5500
    },
    {
      "epoch": 2.7017247617898925,
      "grad_norm": 0.6981664896011353,
      "learning_rate": 0.00016606747233900815,
      "loss": 2.611,
      "step": 5600
    },
    {
      "epoch": 2.749969846821855,
      "grad_norm": 0.5734795928001404,
      "learning_rate": 0.0001649217431041408,
      "loss": 2.6092,
      "step": 5700
    },
    {
      "epoch": 2.7982149318538174,
      "grad_norm": 0.6955406665802002,
      "learning_rate": 0.00016376108929007184,
      "loss": 2.6039,
      "step": 5800
    },
    {
      "epoch": 2.84646001688578,
      "grad_norm": 0.8621996641159058,
      "learning_rate": 0.00016258577771449505,
      "loss": 2.6017,
      "step": 5900
    },
    {
      "epoch": 2.894705101917742,
      "grad_norm": 0.7937944531440735,
      "learning_rate": 0.00016139607856471377,
      "loss": 2.5979,
      "step": 6000
    },
    {
      "epoch": 2.9429501869497043,
      "grad_norm": 0.6987308263778687,
      "learning_rate": 0.00016019226533552864,
      "loss": 2.5936,
      "step": 6100
    },
    {
      "epoch": 2.991195271981667,
      "grad_norm": 0.6699617505073547,
      "learning_rate": 0.0001589746147663651,
      "loss": 2.5915,
      "step": 6200
    },
    {
      "epoch": 3.0394403570136292,
      "grad_norm": 0.7159110903739929,
      "learning_rate": 0.0001577434067776548,
      "loss": 2.5865,
      "step": 6300
    },
    {
      "epoch": 3.0876854420455917,
      "grad_norm": 0.6969411373138428,
      "learning_rate": 0.00015649892440648623,
      "loss": 2.5827,
      "step": 6400
    },
    {
      "epoch": 3.135930527077554,
      "grad_norm": 0.554384171962738,
      "learning_rate": 0.0001552414537415382,
      "loss": 2.5815,
      "step": 6500
    },
    {
      "epoch": 3.184175612109516,
      "grad_norm": 0.7219839096069336,
      "learning_rate": 0.0001539712838573123,
      "loss": 2.5786,
      "step": 6600
    },
    {
      "epoch": 3.2324206971414786,
      "grad_norm": 0.6696949005126953,
      "learning_rate": 0.00015268870674767893,
      "loss": 2.5749,
      "step": 6700
    },
    {
      "epoch": 3.280665782173441,
      "grad_norm": 0.8164668679237366,
      "learning_rate": 0.0001513940172587518,
      "loss": 2.5736,
      "step": 6800
    },
    {
      "epoch": 3.3289108672054035,
      "grad_norm": 0.6077373623847961,
      "learning_rate": 0.00015008751302110737,
      "loss": 2.5696,
      "step": 6900
    },
    {
      "epoch": 3.377155952237366,
      "grad_norm": 1.3647189140319824,
      "learning_rate": 0.00014876949438136347,
      "loss": 2.5682,
      "step": 7000
    },
    {
      "epoch": 3.425401037269328,
      "grad_norm": 0.799738883972168,
      "learning_rate": 0.0001474402643331343,
      "loss": 2.5663,
      "step": 7100
    },
    {
      "epoch": 3.4736461223012904,
      "grad_norm": 0.7075297832489014,
      "learning_rate": 0.00014610012844737622,
      "loss": 2.5631,
      "step": 7200
    },
    {
      "epoch": 3.521891207333253,
      "grad_norm": 0.6022743582725525,
      "learning_rate": 0.00014474939480214156,
      "loss": 2.5609,
      "step": 7300
    },
    {
      "epoch": 3.5701362923652153,
      "grad_norm": 0.8740379214286804,
      "learning_rate": 0.00014338837391175582,
      "loss": 2.5584,
      "step": 7400
    },
    {
      "epoch": 3.618381377397178,
      "grad_norm": 0.6049707531929016,
      "learning_rate": 0.0001420173786554348,
      "loss": 2.5562,
      "step": 7500
    },
    {
      "epoch": 3.6666264624291403,
      "grad_norm": 0.8140528798103333,
      "learning_rate": 0.0001406367242053583,
      "loss": 2.5546,
      "step": 7600
    },
    {
      "epoch": 3.7148715474611023,
      "grad_norm": 0.7048531770706177,
      "learning_rate": 0.00013924672795421637,
      "loss": 2.5518,
      "step": 7700
    },
    {
      "epoch": 3.7631166324930647,
      "grad_norm": 0.7347581386566162,
      "learning_rate": 0.0001378477094422455,
      "loss": 2.5493,
      "step": 7800
    },
    {
      "epoch": 3.811361717525027,
      "grad_norm": 0.6449453830718994,
      "learning_rate": 0.00013643999028377065,
      "loss": 2.5487,
      "step": 7900
    },
    {
      "epoch": 3.8596068025569896,
      "grad_norm": 0.6535289287567139,
      "learning_rate": 0.00013502389409327087,
      "loss": 2.5465,
      "step": 8000
    },
    {
      "epoch": 3.9078518875889516,
      "grad_norm": 0.5532990097999573,
      "learning_rate": 0.00013359974641098497,
      "loss": 2.5444,
      "step": 8100
    },
    {
      "epoch": 3.956096972620914,
      "grad_norm": 0.5547085404396057,
      "learning_rate": 0.0001321678746280744,
      "loss": 2.5432,
      "step": 8200
    },
    {
      "epoch": 4.0043420576528765,
      "grad_norm": 0.6853284239768982,
      "learning_rate": 0.00013072860791136075,
      "loss": 2.5395,
      "step": 8300
    },
    {
      "epoch": 4.052587142684839,
      "grad_norm": 0.8226407170295715,
      "learning_rate": 0.00012928227712765504,
      "loss": 2.5357,
      "step": 8400
    },
    {
      "epoch": 4.1008322277168014,
      "grad_norm": 0.7958946824073792,
      "learning_rate": 0.00012782921476769615,
      "loss": 2.5338,
      "step": 8500
    },
    {
      "epoch": 4.149077312748764,
      "grad_norm": 0.9236618876457214,
      "learning_rate": 0.00012636975486971595,
      "loss": 2.5302,
      "step": 8600
    },
    {
      "epoch": 4.197322397780726,
      "grad_norm": 0.45938292145729065,
      "learning_rate": 0.00012490423294264866,
      "loss": 2.5288,
      "step": 8700
    },
    {
      "epoch": 4.245567482812689,
      "grad_norm": 0.7768141627311707,
      "learning_rate": 0.00012343298588900225,
      "loss": 2.5299,
      "step": 8800
    },
    {
      "epoch": 4.29381256784465,
      "grad_norm": 0.6154760718345642,
      "learning_rate": 0.0001219563519274093,
      "loss": 2.5297,
      "step": 8900
    },
    {
      "epoch": 4.342057652876613,
      "grad_norm": 0.7241714000701904,
      "learning_rate": 0.00012047467051487539,
      "loss": 2.5262,
      "step": 9000
    },
    {
      "epoch": 4.390302737908575,
      "grad_norm": 0.596510112285614,
      "learning_rate": 0.00011898828226874284,
      "loss": 2.5248,
      "step": 9100
    },
    {
      "epoch": 4.438547822940538,
      "grad_norm": 0.6477695107460022,
      "learning_rate": 0.00011749752888838754,
      "loss": 2.5238,
      "step": 9200
    },
    {
      "epoch": 4.4867929079725,
      "grad_norm": 0.6003341674804688,
      "learning_rate": 0.00011600275307666734,
      "loss": 2.5216,
      "step": 9300
    },
    {
      "epoch": 4.535037993004463,
      "grad_norm": 0.5361546277999878,
      "learning_rate": 0.00011450429846113939,
      "loss": 2.5198,
      "step": 9400
    },
    {
      "epoch": 4.583283078036425,
      "grad_norm": 0.5617582201957703,
      "learning_rate": 0.00011300250951506519,
      "loss": 2.5194,
      "step": 9500
    },
    {
      "epoch": 4.6315281630683875,
      "grad_norm": 0.5356466174125671,
      "learning_rate": 0.00011149773147822111,
      "loss": 2.5162,
      "step": 9600
    },
    {
      "epoch": 4.67977324810035,
      "grad_norm": 0.5855473279953003,
      "learning_rate": 0.00010999031027753268,
      "loss": 2.5145,
      "step": 9700
    },
    {
      "epoch": 4.7280183331323125,
      "grad_norm": 0.679783284664154,
      "learning_rate": 0.00010848059244755093,
      "loss": 2.5139,
      "step": 9800
    },
    {
      "epoch": 4.776263418164275,
      "grad_norm": 0.5378139019012451,
      "learning_rate": 0.00010696892505078913,
      "loss": 2.5128,
      "step": 9900
    },
    {
      "epoch": 4.8245085031962365,
      "grad_norm": 0.48252737522125244,
      "learning_rate": 0.00010545565559793796,
      "loss": 2.5115,
      "step": 10000
    },
    {
      "epoch": 4.872753588228199,
      "grad_norm": 0.4901250898838043,
      "learning_rate": 0.00010394113196797793,
      "loss": 2.5099,
      "step": 10100
    },
    {
      "epoch": 4.920998673260161,
      "grad_norm": 0.7089890241622925,
      "learning_rate": 0.00010242570232820687,
      "loss": 2.5105,
      "step": 10200
    },
    {
      "epoch": 4.969243758292124,
      "grad_norm": 0.49930301308631897,
      "learning_rate": 0.00010090971505420139,
      "loss": 2.5076,
      "step": 10300
    },
    {
      "epoch": 5.017488843324086,
      "grad_norm": 0.4562397301197052,
      "learning_rate": 9.939351864973006e-05,
      "loss": 2.5046,
      "step": 10400
    },
    {
      "epoch": 5.065733928356049,
      "grad_norm": 0.6270224452018738,
      "learning_rate": 9.787746166663764e-05,
      "loss": 2.5023,
      "step": 10500
    },
    {
      "epoch": 5.113979013388011,
      "grad_norm": 0.4763181805610657,
      "learning_rate": 9.636189262471799e-05,
      "loss": 2.5011,
      "step": 10600
    },
    {
      "epoch": 5.162224098419974,
      "grad_norm": 0.41499122977256775,
      "learning_rate": 9.484715993159407e-05,
      "loss": 2.5003,
      "step": 10700
    },
    {
      "epoch": 5.210469183451936,
      "grad_norm": 0.5252153873443604,
      "learning_rate": 9.33336118026245e-05,
      "loss": 2.4985,
      "step": 10800
    },
    {
      "epoch": 5.258714268483899,
      "grad_norm": 0.5059440732002258,
      "learning_rate": 9.182159618085328e-05,
      "loss": 2.4974,
      "step": 10900
    },
    {
      "epoch": 5.306959353515861,
      "grad_norm": 0.6075389981269836,
      "learning_rate": 9.031146065702316e-05,
      "loss": 2.4978,
      "step": 11000
    },
    {
      "epoch": 5.355204438547823,
      "grad_norm": 0.5422391891479492,
      "learning_rate": 8.880355238966923e-05,
      "loss": 2.496,
      "step": 11100
    },
    {
      "epoch": 5.403449523579785,
      "grad_norm": 0.6148737668991089,
      "learning_rate": 8.729821802531212e-05,
      "loss": 2.4941,
      "step": 11200
    },
    {
      "epoch": 5.4516946086117475,
      "grad_norm": 0.4883492588996887,
      "learning_rate": 8.579580361876917e-05,
      "loss": 2.4934,
      "step": 11300
    },
    {
      "epoch": 5.49993969364371,
      "grad_norm": 0.5523918867111206,
      "learning_rate": 8.429665455360108e-05,
      "loss": 2.4937,
      "step": 11400
    },
    {
      "epoch": 5.548184778675672,
      "grad_norm": 0.5258156061172485,
      "learning_rate": 8.28011154627134e-05,
      "loss": 2.4907,
      "step": 11500
    },
    {
      "epoch": 5.596429863707635,
      "grad_norm": 0.4988797903060913,
      "learning_rate": 8.130953014913025e-05,
      "loss": 2.4906,
      "step": 11600
    },
    {
      "epoch": 5.644674948739597,
      "grad_norm": 0.45411014556884766,
      "learning_rate": 7.982224150695896e-05,
      "loss": 2.4912,
      "step": 11700
    },
    {
      "epoch": 5.69292003377156,
      "grad_norm": 0.4481936991214752,
      "learning_rate": 7.833959144256369e-05,
      "loss": 2.4891,
      "step": 11800
    },
    {
      "epoch": 5.741165118803522,
      "grad_norm": 0.5340952277183533,
      "learning_rate": 7.686192079596586e-05,
      "loss": 2.4879,
      "step": 11900
    },
    {
      "epoch": 5.789410203835484,
      "grad_norm": 0.44194942712783813,
      "learning_rate": 7.538956926249014e-05,
      "loss": 2.4866,
      "step": 12000
    },
    {
      "epoch": 5.837655288867447,
      "grad_norm": 0.5398260951042175,
      "learning_rate": 7.392287531467316e-05,
      "loss": 2.4846,
      "step": 12100
    },
    {
      "epoch": 5.885900373899409,
      "grad_norm": 0.4266635775566101,
      "learning_rate": 7.246217612445368e-05,
      "loss": 2.4854,
      "step": 12200
    },
    {
      "epoch": 5.934145458931371,
      "grad_norm": 0.48854753375053406,
      "learning_rate": 7.100780748566154e-05,
      "loss": 2.4846,
      "step": 12300
    },
    {
      "epoch": 5.982390543963334,
      "grad_norm": 0.49039462208747864,
      "learning_rate": 6.956010373682335e-05,
      "loss": 2.4827,
      "step": 12400
    },
    {
      "epoch": 6.030635628995296,
      "grad_norm": 0.5125871300697327,
      "learning_rate": 6.811939768430303e-05,
      "loss": 2.4796,
      "step": 12500
    },
    {
      "epoch": 6.0788807140272585,
      "grad_norm": 0.7135576605796814,
      "learning_rate": 6.668602052579424e-05,
      "loss": 2.4785,
      "step": 12600
    },
    {
      "epoch": 6.127125799059221,
      "grad_norm": 0.4768633544445038,
      "learning_rate": 6.526030177418294e-05,
      "loss": 2.4779,
      "step": 12700
    },
    {
      "epoch": 6.175370884091183,
      "grad_norm": 0.6368355751037598,
      "learning_rate": 6.384256918179691e-05,
      "loss": 2.4781,
      "step": 12800
    },
    {
      "epoch": 6.223615969123146,
      "grad_norm": 0.39956721663475037,
      "learning_rate": 6.24331486650603e-05,
      "loss": 2.4768,
      "step": 12900
    },
    {
      "epoch": 6.271861054155108,
      "grad_norm": 0.41272154450416565,
      "learning_rate": 6.103236422957008e-05,
      "loss": 2.4762,
      "step": 13000
    },
    {
      "epoch": 6.32010613918707,
      "grad_norm": 0.4090198278427124,
      "learning_rate": 5.964053789561177e-05,
      "loss": 2.4753,
      "step": 13100
    },
    {
      "epoch": 6.368351224219032,
      "grad_norm": 0.5153887271881104,
      "learning_rate": 5.825798962413164e-05,
      "loss": 2.474,
      "step": 13200
    },
    {
      "epoch": 6.416596309250995,
      "grad_norm": 0.5258684158325195,
      "learning_rate": 5.688503724318217e-05,
      "loss": 2.4744,
      "step": 13300
    },
    {
      "epoch": 6.464841394282957,
      "grad_norm": 0.44190916419029236,
      "learning_rate": 5.5521996374858134e-05,
      "loss": 2.4733,
      "step": 13400
    },
    {
      "epoch": 6.51308647931492,
      "grad_norm": 0.4085471034049988,
      "learning_rate": 5.416918036273935e-05,
      "loss": 2.4729,
      "step": 13500
    },
    {
      "epoch": 6.561331564346882,
      "grad_norm": 0.4102930724620819,
      "learning_rate": 5.282690019985757e-05,
      "loss": 2.4716,
      "step": 13600
    },
    {
      "epoch": 6.609576649378845,
      "grad_norm": 0.40246206521987915,
      "learning_rate": 5.1495464457203804e-05,
      "loss": 2.4725,
      "step": 13700
    },
    {
      "epoch": 6.657821734410807,
      "grad_norm": 0.4583997428417206,
      "learning_rate": 5.017517921279198e-05,
      "loss": 2.4704,
      "step": 13800
    },
    {
      "epoch": 6.7060668194427695,
      "grad_norm": 0.35788264870643616,
      "learning_rate": 4.8866347981296125e-05,
      "loss": 2.4687,
      "step": 13900
    },
    {
      "epoch": 6.754311904474732,
      "grad_norm": 0.4439219534397125,
      "learning_rate": 4.756927164427685e-05,
      "loss": 2.469,
      "step": 14000
    },
    {
      "epoch": 6.802556989506694,
      "grad_norm": 0.38770484924316406,
      "learning_rate": 4.628424838101263e-05,
      "loss": 2.4684,
      "step": 14100
    },
    {
      "epoch": 6.850802074538656,
      "grad_norm": 0.391055703163147,
      "learning_rate": 4.501157359995305e-05,
      "loss": 2.4668,
      "step": 14200
    },
    {
      "epoch": 6.899047159570618,
      "grad_norm": 0.4599634110927582,
      "learning_rate": 4.375153987080829e-05,
      "loss": 2.4652,
      "step": 14300
    },
    {
      "epoch": 6.947292244602581,
      "grad_norm": 0.4245084524154663,
      "learning_rate": 4.250443685729169e-05,
      "loss": 2.4655,
      "step": 14400
    },
    {
      "epoch": 6.995537329634543,
      "grad_norm": 0.45656418800354004,
      "learning_rate": 4.1270551250530374e-05,
      "loss": 2.4658,
      "step": 14500
    },
    {
      "epoch": 7.043782414666506,
      "grad_norm": 0.5119195580482483,
      "learning_rate": 4.0050166703158674e-05,
      "loss": 2.4628,
      "step": 14600
    },
    {
      "epoch": 7.092027499698468,
      "grad_norm": 0.47480058670043945,
      "learning_rate": 3.884356376411089e-05,
      "loss": 2.4623,
      "step": 14700
    },
    {
      "epoch": 7.140272584730431,
      "grad_norm": 0.35031041502952576,
      "learning_rate": 3.7651019814126654e-05,
      "loss": 2.4626,
      "step": 14800
    },
    {
      "epoch": 7.188517669762393,
      "grad_norm": 0.6267052888870239,
      "learning_rate": 3.647280900198553e-05,
      "loss": 2.4621,
      "step": 14900
    },
    {
      "epoch": 7.236762754794356,
      "grad_norm": 0.47094637155532837,
      "learning_rate": 3.530920218148376e-05,
      "loss": 2.4603,
      "step": 15000
    },
    {
      "epoch": 7.285007839826318,
      "grad_norm": 0.42287275195121765,
      "learning_rate": 3.41604668491691e-05,
      "loss": 2.461,
      "step": 15100
    },
    {
      "epoch": 7.3332529248582805,
      "grad_norm": 0.3883097767829895,
      "learning_rate": 3.3026867082847056e-05,
      "loss": 2.4608,
      "step": 15200
    },
    {
      "epoch": 7.381498009890242,
      "grad_norm": 0.5106400847434998,
      "learning_rate": 3.190866348087318e-05,
      "loss": 2.4596,
      "step": 15300
    },
    {
      "epoch": 7.4297430949222045,
      "grad_norm": 0.4181070327758789,
      "learning_rate": 3.080611310224539e-05,
      "loss": 2.4598,
      "step": 15400
    },
    {
      "epoch": 7.477988179954167,
      "grad_norm": 0.3670555353164673,
      "learning_rate": 2.971946940750958e-05,
      "loss": 2.459,
      "step": 15500
    },
    {
      "epoch": 7.526233264986129,
      "grad_norm": 0.3955056071281433,
      "learning_rate": 2.864898220049277e-05,
      "loss": 2.4569,
      "step": 15600
    },
    {
      "epoch": 7.574478350018092,
      "grad_norm": 0.4181554913520813,
      "learning_rate": 2.7594897570876866e-05,
      "loss": 2.4567,
      "step": 15700
    },
    {
      "epoch": 7.622723435050054,
      "grad_norm": 0.4531964659690857,
      "learning_rate": 2.6557457837625955e-05,
      "loss": 2.4561,
      "step": 15800
    },
    {
      "epoch": 7.670968520082017,
      "grad_norm": 0.40635260939598083,
      "learning_rate": 2.5536901493280894e-05,
      "loss": 2.458,
      "step": 15900
    },
    {
      "epoch": 7.719213605113979,
      "grad_norm": 0.37201112508773804,
      "learning_rate": 2.4533463149133073e-05,
      "loss": 2.4569,
      "step": 16000
    },
    {
      "epoch": 7.767458690145942,
      "grad_norm": 0.3365475535392761,
      "learning_rate": 2.354737348129077e-05,
      "loss": 2.455,
      "step": 16100
    },
    {
      "epoch": 7.815703775177903,
      "grad_norm": 0.3770780861377716,
      "learning_rate": 2.2578859177649924e-05,
      "loss": 2.457,
      "step": 16200
    },
    {
      "epoch": 7.863948860209867,
      "grad_norm": 0.38772594928741455,
      "learning_rate": 2.1628142885781966e-05,
      "loss": 2.4545,
      "step": 16300
    },
    {
      "epoch": 7.912193945241828,
      "grad_norm": 0.3591633141040802,
      "learning_rate": 2.069544316175025e-05,
      "loss": 2.4533,
      "step": 16400
    },
    {
      "epoch": 7.960439030273791,
      "grad_norm": 0.3850359618663788,
      "learning_rate": 1.9780974419866993e-05,
      "loss": 2.4544,
      "step": 16500
    },
    {
      "epoch": 8.008684115305753,
      "grad_norm": 0.33803796768188477,
      "learning_rate": 1.8884946883402843e-05,
      "loss": 2.4529,
      "step": 16600
    },
    {
      "epoch": 8.056929200337716,
      "grad_norm": 0.35733097791671753,
      "learning_rate": 1.8007566536259222e-05,
      "loss": 2.4513,
      "step": 16700
    },
    {
      "epoch": 8.105174285369678,
      "grad_norm": 0.330173522233963,
      "learning_rate": 1.7149035075615794e-05,
      "loss": 2.4503,
      "step": 16800
    },
    {
      "epoch": 8.15341937040164,
      "grad_norm": 0.3115040063858032,
      "learning_rate": 1.6309549865563044e-05,
      "loss": 2.4519,
      "step": 16900
    },
    {
      "epoch": 8.201664455433603,
      "grad_norm": 0.357662558555603,
      "learning_rate": 1.5489303891731143e-05,
      "loss": 2.4506,
      "step": 17000
    },
    {
      "epoch": 8.249909540465564,
      "grad_norm": 0.34802350401878357,
      "learning_rate": 1.4688485716925392e-05,
      "loss": 2.4506,
      "step": 17100
    },
    {
      "epoch": 8.298154625497528,
      "grad_norm": 0.31058865785598755,
      "learning_rate": 1.3907279437778153e-05,
      "loss": 2.4499,
      "step": 17200
    },
    {
      "epoch": 8.34639971052949,
      "grad_norm": 0.306403785943985,
      "learning_rate": 1.3145864642427841e-05,
      "loss": 2.4503,
      "step": 17300
    },
    {
      "epoch": 8.394644795561453,
      "grad_norm": 0.3197612166404724,
      "learning_rate": 1.2404416369234128e-05,
      "loss": 2.4496,
      "step": 17400
    },
    {
      "epoch": 8.442889880593414,
      "grad_norm": 0.29585206508636475,
      "learning_rate": 1.1683105066539068e-05,
      "loss": 2.4498,
      "step": 17500
    },
    {
      "epoch": 8.491134965625378,
      "grad_norm": 0.3000775873661041,
      "learning_rate": 1.0982096553483568e-05,
      "loss": 2.4493,
      "step": 17600
    },
    {
      "epoch": 8.53938005065734,
      "grad_norm": 0.3009583055973053,
      "learning_rate": 1.0301551981887847e-05,
      "loss": 2.4488,
      "step": 17700
    },
    {
      "epoch": 8.5876251356893,
      "grad_norm": 0.3033211827278137,
      "learning_rate": 9.641627799205011e-06,
      "loss": 2.4499,
      "step": 17800
    },
    {
      "epoch": 8.635870220721264,
      "grad_norm": 0.30003535747528076,
      "learning_rate": 9.002475712555957e-06,
      "loss": 2.4504,
      "step": 17900
    },
    {
      "epoch": 8.684115305753226,
      "grad_norm": 0.3213978111743927,
      "learning_rate": 8.384242653854146e-06,
      "loss": 2.448,
      "step": 18000
    },
    {
      "epoch": 8.732360390785189,
      "grad_norm": 0.2975524961948395,
      "learning_rate": 7.78707074602808e-06,
      "loss": 2.4487,
      "step": 18100
    },
    {
      "epoch": 8.78060547581715,
      "grad_norm": 0.28831279277801514,
      "learning_rate": 7.211097270349066e-06,
      "loss": 2.4484,
      "step": 18200
    },
    {
      "epoch": 8.828850560849114,
      "grad_norm": 0.28893449902534485,
      "learning_rate": 6.656454634872555e-06,
      "loss": 2.4468,
      "step": 18300
    },
    {
      "epoch": 8.877095645881075,
      "grad_norm": 0.28152674436569214,
      "learning_rate": 6.123270343999132e-06,
      "loss": 2.449,
      "step": 18400
    },
    {
      "epoch": 8.925340730913039,
      "grad_norm": 0.28913310170173645,
      "learning_rate": 5.611666969163243e-06,
      "loss": 2.446,
      "step": 18500
    },
    {
      "epoch": 8.973585815945,
      "grad_norm": 0.2871024012565613,
      "learning_rate": 5.121762120655727e-06,
      "loss": 2.4473,
      "step": 18600
    },
    {
      "epoch": 9.021830900976964,
      "grad_norm": 0.28578582406044006,
      "learning_rate": 4.653668420586843e-06,
      "loss": 2.4486,
      "step": 18700
    },
    {
      "epoch": 9.070075986008925,
      "grad_norm": 0.28224024176597595,
      "learning_rate": 4.207493476996205e-06,
      "loss": 2.4463,
      "step": 18800
    },
    {
      "epoch": 9.118321071040887,
      "grad_norm": 0.29887914657592773,
      "learning_rate": 3.783339859115065e-06,
      "loss": 2.446,
      "step": 18900
    },
    {
      "epoch": 9.16656615607285,
      "grad_norm": 0.2856266498565674,
      "learning_rate": 3.381305073787211e-06,
      "loss": 2.4453,
      "step": 19000
    },
    {
      "epoch": 9.214811241104812,
      "grad_norm": 0.2867438793182373,
      "learning_rate": 3.0014815430535524e-06,
      "loss": 2.4451,
      "step": 19100
    },
    {
      "epoch": 9.263056326136775,
      "grad_norm": 0.27781984210014343,
      "learning_rate": 2.6439565829055268e-06,
      "loss": 2.4455,
      "step": 19200
    },
    {
      "epoch": 9.311301411168737,
      "grad_norm": 0.27015501260757446,
      "learning_rate": 2.3088123832125218e-06,
      "loss": 2.4447,
      "step": 19300
    },
    {
      "epoch": 9.3595464962007,
      "grad_norm": 0.2683597207069397,
      "learning_rate": 1.9961259888275017e-06,
      "loss": 2.4446,
      "step": 19400
    },
    {
      "epoch": 9.407791581232662,
      "grad_norm": 0.2728540003299713,
      "learning_rate": 1.7059692818755412e-06,
      "loss": 2.4451,
      "step": 19500
    },
    {
      "epoch": 9.456036666264625,
      "grad_norm": 0.26194703578948975,
      "learning_rate": 1.4384089652291543e-06,
      "loss": 2.4459,
      "step": 19600
    },
    {
      "epoch": 9.504281751296586,
      "grad_norm": 0.26517143845558167,
      "learning_rate": 1.1935065471742612e-06,
      "loss": 2.4441,
      "step": 19700
    },
    {
      "epoch": 9.55252683632855,
      "grad_norm": 0.2607557773590088,
      "learning_rate": 9.713183272703208e-07,
      "loss": 2.4449,
      "step": 19800
    },
    {
      "epoch": 9.600771921360511,
      "grad_norm": 0.259233295917511,
      "learning_rate": 7.718953834078058e-07,
      "loss": 2.4458,
      "step": 19900
    },
    {
      "epoch": 9.649017006392473,
      "grad_norm": 0.2586885094642639,
      "learning_rate": 5.952835600662288e-07,
      "loss": 2.4459,
      "step": 20000
    },
    {
      "epoch": 9.697262091424436,
      "grad_norm": 0.25183719396591187,
      "learning_rate": 4.415234577750726e-07,
      "loss": 2.4448,
      "step": 20100
    },
    {
      "epoch": 9.745507176456398,
      "grad_norm": 0.2551169991493225,
      "learning_rate": 3.1065042378034535e-07,
      "loss": 2.4454,
      "step": 20200
    },
    {
      "epoch": 9.793752261488361,
      "grad_norm": 0.2578144669532776,
      "learning_rate": 2.0269454391874666e-07,
      "loss": 2.4434,
      "step": 20300
    },
    {
      "epoch": 9.841997346520323,
      "grad_norm": 0.2600604295730591,
      "learning_rate": 1.1768063570136711e-07,
      "loss": 2.445,
      "step": 20400
    },
    {
      "epoch": 9.890242431552286,
      "grad_norm": 0.2532850205898285,
      "learning_rate": 5.562824260848531e-08,
      "loss": 2.4442,
      "step": 20500
    },
    {
      "epoch": 9.938487516584248,
      "grad_norm": 0.2574668228626251,
      "learning_rate": 1.6551629596817108e-08,
      "loss": 2.4451,
      "step": 20600
    },
    {
      "epoch": 9.986732601616211,
      "grad_norm": 0.25438565015792847,
      "learning_rate": 4.597798201944059e-10,
      "loss": 2.4445,
      "step": 20700
    },
    {
      "epoch": 9.996381618622603,
      "step": 20720,
      "total_flos": 1.2537451970195096e+19,
      "train_loss": 2.6364351248649096,
      "train_runtime": 68858.2851,
      "train_samples_per_second": 1887.935,
      "train_steps_per_second": 0.301
    }
  ],
  "logging_steps": 100,
  "max_steps": 20720,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2537451970195096e+19,
  "train_batch_size": 196,
  "trial_name": null,
  "trial_params": null
}
