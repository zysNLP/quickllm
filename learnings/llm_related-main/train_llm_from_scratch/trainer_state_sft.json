{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.99910031488979,
  "eval_steps": 500,
  "global_step": 55570,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01799370220422852,
      "grad_norm": 1.2284046411514282,
      "learning_rate": 0.00019999840195943463,
      "loss": 2.8199,
      "step": 100
    },
    {
      "epoch": 0.03598740440845704,
      "grad_norm": 1.0752545595169067,
      "learning_rate": 0.00019999360788881308,
      "loss": 2.3096,
      "step": 200
    },
    {
      "epoch": 0.05398110661268556,
      "grad_norm": 1.0205307006835938,
      "learning_rate": 0.00019998561794135782,
      "loss": 2.2412,
      "step": 300
    },
    {
      "epoch": 0.07197480881691408,
      "grad_norm": 0.8182767629623413,
      "learning_rate": 0.000199974432372434,
      "loss": 2.19,
      "step": 400
    },
    {
      "epoch": 0.0899685110211426,
      "grad_norm": 0.8404520750045776,
      "learning_rate": 0.00019996005153954152,
      "loss": 2.1598,
      "step": 500
    },
    {
      "epoch": 0.10796221322537113,
      "grad_norm": 0.8655837774276733,
      "learning_rate": 0.00019994247590230342,
      "loss": 2.1289,
      "step": 600
    },
    {
      "epoch": 0.12595591542959964,
      "grad_norm": 0.8855652809143066,
      "learning_rate": 0.00019992170602245137,
      "loss": 2.107,
      "step": 700
    },
    {
      "epoch": 0.14394961763382816,
      "grad_norm": 0.7325643301010132,
      "learning_rate": 0.00019989774256380755,
      "loss": 2.0913,
      "step": 800
    },
    {
      "epoch": 0.16194331983805668,
      "grad_norm": 0.8457645177841187,
      "learning_rate": 0.0001998705862922636,
      "loss": 2.0762,
      "step": 900
    },
    {
      "epoch": 0.1799370220422852,
      "grad_norm": 0.7591747641563416,
      "learning_rate": 0.0001998402380757559,
      "loss": 2.0604,
      "step": 1000
    },
    {
      "epoch": 0.19793072424651373,
      "grad_norm": 0.8518025875091553,
      "learning_rate": 0.0001998066988842381,
      "loss": 2.048,
      "step": 1100
    },
    {
      "epoch": 0.21592442645074225,
      "grad_norm": 0.7283785939216614,
      "learning_rate": 0.00019976996978965,
      "loss": 2.0353,
      "step": 1200
    },
    {
      "epoch": 0.23391812865497075,
      "grad_norm": 0.8715572357177734,
      "learning_rate": 0.00019973005196588327,
      "loss": 2.0263,
      "step": 1300
    },
    {
      "epoch": 0.25191183085919927,
      "grad_norm": 0.7974886894226074,
      "learning_rate": 0.0001996869466887439,
      "loss": 2.0202,
      "step": 1400
    },
    {
      "epoch": 0.2699055330634278,
      "grad_norm": 0.6409863233566284,
      "learning_rate": 0.00019964065533591152,
      "loss": 2.0103,
      "step": 1500
    },
    {
      "epoch": 0.2878992352676563,
      "grad_norm": 0.7986435294151306,
      "learning_rate": 0.0001995911793868954,
      "loss": 1.9976,
      "step": 1600
    },
    {
      "epoch": 0.30589293747188484,
      "grad_norm": 0.7317022085189819,
      "learning_rate": 0.00019953852042298688,
      "loss": 1.9939,
      "step": 1700
    },
    {
      "epoch": 0.32388663967611336,
      "grad_norm": 0.6630493998527527,
      "learning_rate": 0.0001994826801272093,
      "loss": 1.9841,
      "step": 1800
    },
    {
      "epoch": 0.3418803418803419,
      "grad_norm": 0.6765059232711792,
      "learning_rate": 0.0001994236602842637,
      "loss": 1.9766,
      "step": 1900
    },
    {
      "epoch": 0.3598740440845704,
      "grad_norm": 0.7228472828865051,
      "learning_rate": 0.00019936146278047226,
      "loss": 1.9722,
      "step": 2000
    },
    {
      "epoch": 0.37786774628879893,
      "grad_norm": 0.626101553440094,
      "learning_rate": 0.00019929608960371758,
      "loss": 1.9675,
      "step": 2100
    },
    {
      "epoch": 0.39586144849302746,
      "grad_norm": 0.6248858571052551,
      "learning_rate": 0.00019922754284337947,
      "loss": 1.9611,
      "step": 2200
    },
    {
      "epoch": 0.413855150697256,
      "grad_norm": 0.645107090473175,
      "learning_rate": 0.00019915582469026797,
      "loss": 1.9515,
      "step": 2300
    },
    {
      "epoch": 0.4318488529014845,
      "grad_norm": 0.6384338140487671,
      "learning_rate": 0.00019908093743655348,
      "loss": 1.9552,
      "step": 2400
    },
    {
      "epoch": 0.449842555105713,
      "grad_norm": 0.6384785175323486,
      "learning_rate": 0.0001990028834756933,
      "loss": 1.9437,
      "step": 2500
    },
    {
      "epoch": 0.4678362573099415,
      "grad_norm": 0.716632068157196,
      "learning_rate": 0.00019892166530235546,
      "loss": 1.9417,
      "step": 2600
    },
    {
      "epoch": 0.48582995951417,
      "grad_norm": 0.5962179899215698,
      "learning_rate": 0.0001988372855123386,
      "loss": 1.9329,
      "step": 2700
    },
    {
      "epoch": 0.5038236617183985,
      "grad_norm": 0.6342476606369019,
      "learning_rate": 0.00019874974680248928,
      "loss": 1.9354,
      "step": 2800
    },
    {
      "epoch": 0.5218173639226271,
      "grad_norm": 0.6331775784492493,
      "learning_rate": 0.0001986590519706157,
      "loss": 1.9313,
      "step": 2900
    },
    {
      "epoch": 0.5398110661268556,
      "grad_norm": 0.6975757479667664,
      "learning_rate": 0.00019856520391539823,
      "loss": 1.9252,
      "step": 3000
    },
    {
      "epoch": 0.5578047683310842,
      "grad_norm": 0.7066127061843872,
      "learning_rate": 0.00019846820563629693,
      "loss": 1.9205,
      "step": 3100
    },
    {
      "epoch": 0.5757984705353126,
      "grad_norm": 0.582149863243103,
      "learning_rate": 0.00019836806023345544,
      "loss": 1.9145,
      "step": 3200
    },
    {
      "epoch": 0.5937921727395412,
      "grad_norm": 0.5883142948150635,
      "learning_rate": 0.00019826477090760208,
      "loss": 1.9136,
      "step": 3300
    },
    {
      "epoch": 0.6117858749437697,
      "grad_norm": 0.6636272072792053,
      "learning_rate": 0.0001981583409599475,
      "loss": 1.9096,
      "step": 3400
    },
    {
      "epoch": 0.6297795771479981,
      "grad_norm": 0.6050708293914795,
      "learning_rate": 0.00019804877379207922,
      "loss": 1.9043,
      "step": 3500
    },
    {
      "epoch": 0.6477732793522267,
      "grad_norm": 0.6300317645072937,
      "learning_rate": 0.00019793607290585278,
      "loss": 1.9036,
      "step": 3600
    },
    {
      "epoch": 0.6657669815564552,
      "grad_norm": 0.5627692937850952,
      "learning_rate": 0.00019782024190327996,
      "loss": 1.8937,
      "step": 3700
    },
    {
      "epoch": 0.6837606837606838,
      "grad_norm": 0.7251080274581909,
      "learning_rate": 0.00019770128448641354,
      "loss": 1.8977,
      "step": 3800
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.5676718950271606,
      "learning_rate": 0.00019757920445722911,
      "loss": 1.8884,
      "step": 3900
    },
    {
      "epoch": 0.7197480881691408,
      "grad_norm": 0.6762987375259399,
      "learning_rate": 0.00019745400571750347,
      "loss": 1.8889,
      "step": 4000
    },
    {
      "epoch": 0.7377417903733693,
      "grad_norm": 0.5320459008216858,
      "learning_rate": 0.00019732569226868984,
      "loss": 1.8862,
      "step": 4100
    },
    {
      "epoch": 0.7557354925775979,
      "grad_norm": 0.530092716217041,
      "learning_rate": 0.00019719426821179022,
      "loss": 1.8801,
      "step": 4200
    },
    {
      "epoch": 0.7737291947818263,
      "grad_norm": 0.5418474674224854,
      "learning_rate": 0.00019705973774722404,
      "loss": 1.8802,
      "step": 4300
    },
    {
      "epoch": 0.7917228969860549,
      "grad_norm": 0.5227158665657043,
      "learning_rate": 0.0001969221051746941,
      "loss": 1.8773,
      "step": 4400
    },
    {
      "epoch": 0.8097165991902834,
      "grad_norm": 0.5986514687538147,
      "learning_rate": 0.00019678137489304913,
      "loss": 1.8742,
      "step": 4500
    },
    {
      "epoch": 0.827710301394512,
      "grad_norm": 0.5671933889389038,
      "learning_rate": 0.00019663755140014307,
      "loss": 1.8721,
      "step": 4600
    },
    {
      "epoch": 0.8457040035987404,
      "grad_norm": 0.5462867617607117,
      "learning_rate": 0.00019649063929269141,
      "loss": 1.8708,
      "step": 4700
    },
    {
      "epoch": 0.863697705802969,
      "grad_norm": 0.5217745304107666,
      "learning_rate": 0.00019634064326612438,
      "loss": 1.8675,
      "step": 4800
    },
    {
      "epoch": 0.8816914080071975,
      "grad_norm": 0.5561423301696777,
      "learning_rate": 0.00019618756811443658,
      "loss": 1.863,
      "step": 4900
    },
    {
      "epoch": 0.899685110211426,
      "grad_norm": 0.5968555212020874,
      "learning_rate": 0.00019603141873003415,
      "loss": 1.8595,
      "step": 5000
    },
    {
      "epoch": 0.9176788124156545,
      "grad_norm": 0.4909781515598297,
      "learning_rate": 0.000195872200103578,
      "loss": 1.8585,
      "step": 5100
    },
    {
      "epoch": 0.935672514619883,
      "grad_norm": 0.48670801520347595,
      "learning_rate": 0.0001957099173238247,
      "loss": 1.8566,
      "step": 5200
    },
    {
      "epoch": 0.9536662168241116,
      "grad_norm": 0.5083125829696655,
      "learning_rate": 0.00019554457557746345,
      "loss": 1.8573,
      "step": 5300
    },
    {
      "epoch": 0.97165991902834,
      "grad_norm": 0.5372658967971802,
      "learning_rate": 0.0001953761801489507,
      "loss": 1.85,
      "step": 5400
    },
    {
      "epoch": 0.9896536212325686,
      "grad_norm": 0.519303560256958,
      "learning_rate": 0.00019520473642034092,
      "loss": 1.8495,
      "step": 5500
    },
    {
      "epoch": 1.007647323436797,
      "grad_norm": 0.5335996150970459,
      "learning_rate": 0.0001950302498711148,
      "loss": 1.8445,
      "step": 5600
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 0.5286354422569275,
      "learning_rate": 0.00019485272607800398,
      "loss": 1.8401,
      "step": 5700
    },
    {
      "epoch": 1.0436347278452542,
      "grad_norm": 0.6177428960800171,
      "learning_rate": 0.00019467217071481293,
      "loss": 1.8368,
      "step": 5800
    },
    {
      "epoch": 1.0616284300494827,
      "grad_norm": 0.5113688707351685,
      "learning_rate": 0.00019448858955223755,
      "loss": 1.8348,
      "step": 5900
    },
    {
      "epoch": 1.0796221322537112,
      "grad_norm": 0.4932892322540283,
      "learning_rate": 0.00019430198845768075,
      "loss": 1.8305,
      "step": 6000
    },
    {
      "epoch": 1.0976158344579396,
      "grad_norm": 0.5082204341888428,
      "learning_rate": 0.00019411237339506484,
      "loss": 1.8349,
      "step": 6100
    },
    {
      "epoch": 1.1156095366621683,
      "grad_norm": 0.6514427661895752,
      "learning_rate": 0.00019391975042464115,
      "loss": 1.8298,
      "step": 6200
    },
    {
      "epoch": 1.1336032388663968,
      "grad_norm": 0.4771674573421478,
      "learning_rate": 0.000193724125702796,
      "loss": 1.8276,
      "step": 6300
    },
    {
      "epoch": 1.1515969410706253,
      "grad_norm": 0.5268054604530334,
      "learning_rate": 0.0001935255054818543,
      "loss": 1.8271,
      "step": 6400
    },
    {
      "epoch": 1.1695906432748537,
      "grad_norm": 0.5408535003662109,
      "learning_rate": 0.00019332389610987935,
      "loss": 1.8228,
      "step": 6500
    },
    {
      "epoch": 1.1875843454790824,
      "grad_norm": 0.5193129181861877,
      "learning_rate": 0.00019311930403047035,
      "loss": 1.8235,
      "step": 6600
    },
    {
      "epoch": 1.205578047683311,
      "grad_norm": 0.5692002177238464,
      "learning_rate": 0.00019291173578255607,
      "loss": 1.8223,
      "step": 6700
    },
    {
      "epoch": 1.2235717498875394,
      "grad_norm": 0.5314545631408691,
      "learning_rate": 0.00019270119800018616,
      "loss": 1.8226,
      "step": 6800
    },
    {
      "epoch": 1.2415654520917678,
      "grad_norm": 0.4665652811527252,
      "learning_rate": 0.00019248769741231892,
      "loss": 1.8159,
      "step": 6900
    },
    {
      "epoch": 1.2595591542959963,
      "grad_norm": 0.5804181694984436,
      "learning_rate": 0.0001922712408426064,
      "loss": 1.8149,
      "step": 7000
    },
    {
      "epoch": 1.277552856500225,
      "grad_norm": 0.521771252155304,
      "learning_rate": 0.00019205183520917615,
      "loss": 1.8113,
      "step": 7100
    },
    {
      "epoch": 1.2955465587044535,
      "grad_norm": 0.5280562043190002,
      "learning_rate": 0.00019182948752441022,
      "loss": 1.8166,
      "step": 7200
    },
    {
      "epoch": 1.313540260908682,
      "grad_norm": 0.4981229603290558,
      "learning_rate": 0.00019160420489472099,
      "loss": 1.8106,
      "step": 7300
    },
    {
      "epoch": 1.3315339631129106,
      "grad_norm": 0.5241571664810181,
      "learning_rate": 0.00019137599452032414,
      "loss": 1.8118,
      "step": 7400
    },
    {
      "epoch": 1.349527665317139,
      "grad_norm": 0.5146917104721069,
      "learning_rate": 0.0001911448636950083,
      "loss": 1.8075,
      "step": 7500
    },
    {
      "epoch": 1.3675213675213675,
      "grad_norm": 0.5059802532196045,
      "learning_rate": 0.00019091081980590225,
      "loss": 1.8079,
      "step": 7600
    },
    {
      "epoch": 1.385515069725596,
      "grad_norm": 0.5192126631736755,
      "learning_rate": 0.00019067387033323848,
      "loss": 1.8062,
      "step": 7700
    },
    {
      "epoch": 1.4035087719298245,
      "grad_norm": 0.5117544531822205,
      "learning_rate": 0.00019043402285011447,
      "loss": 1.807,
      "step": 7800
    },
    {
      "epoch": 1.4215024741340532,
      "grad_norm": 0.47806188464164734,
      "learning_rate": 0.0001901912850222503,
      "loss": 1.8046,
      "step": 7900
    },
    {
      "epoch": 1.4394961763382816,
      "grad_norm": 0.48371195793151855,
      "learning_rate": 0.0001899456646077439,
      "loss": 1.8034,
      "step": 8000
    },
    {
      "epoch": 1.45748987854251,
      "grad_norm": 0.47333788871765137,
      "learning_rate": 0.00018969716945682301,
      "loss": 1.7997,
      "step": 8100
    },
    {
      "epoch": 1.4754835807467386,
      "grad_norm": 0.5049427151679993,
      "learning_rate": 0.00018944580751159427,
      "loss": 1.8001,
      "step": 8200
    },
    {
      "epoch": 1.493477282950967,
      "grad_norm": 0.49197977781295776,
      "learning_rate": 0.00018919158680578933,
      "loss": 1.8001,
      "step": 8300
    },
    {
      "epoch": 1.5114709851551957,
      "grad_norm": 0.445428729057312,
      "learning_rate": 0.0001889345154645082,
      "loss": 1.7977,
      "step": 8400
    },
    {
      "epoch": 1.5294646873594242,
      "grad_norm": 0.48087289929389954,
      "learning_rate": 0.00018867460170395958,
      "loss": 1.7991,
      "step": 8500
    },
    {
      "epoch": 1.5474583895636527,
      "grad_norm": 0.49808216094970703,
      "learning_rate": 0.00018841185383119808,
      "loss": 1.7944,
      "step": 8600
    },
    {
      "epoch": 1.5654520917678814,
      "grad_norm": 0.5247073769569397,
      "learning_rate": 0.0001881462802438589,
      "loss": 1.7922,
      "step": 8700
    },
    {
      "epoch": 1.5834457939721096,
      "grad_norm": 0.5095207095146179,
      "learning_rate": 0.00018787788942988934,
      "loss": 1.7893,
      "step": 8800
    },
    {
      "epoch": 1.6014394961763383,
      "grad_norm": 0.4537122845649719,
      "learning_rate": 0.00018760668996727756,
      "loss": 1.7887,
      "step": 8900
    },
    {
      "epoch": 1.6194331983805668,
      "grad_norm": 0.48096412420272827,
      "learning_rate": 0.0001873326905237784,
      "loss": 1.789,
      "step": 9000
    },
    {
      "epoch": 1.6374269005847952,
      "grad_norm": 0.4950626790523529,
      "learning_rate": 0.0001870558998566364,
      "loss": 1.7886,
      "step": 9100
    },
    {
      "epoch": 1.655420602789024,
      "grad_norm": 0.49376413226127625,
      "learning_rate": 0.00018677632681230586,
      "loss": 1.7843,
      "step": 9200
    },
    {
      "epoch": 1.6734143049932524,
      "grad_norm": 0.4684549868106842,
      "learning_rate": 0.00018649398032616804,
      "loss": 1.7852,
      "step": 9300
    },
    {
      "epoch": 1.6914080071974809,
      "grad_norm": 0.49474549293518066,
      "learning_rate": 0.00018620886942224575,
      "loss": 1.7871,
      "step": 9400
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 0.5288394689559937,
      "learning_rate": 0.00018592100321291474,
      "loss": 1.7813,
      "step": 9500
    },
    {
      "epoch": 1.7273954116059378,
      "grad_norm": 0.4752837121486664,
      "learning_rate": 0.00018563039089861268,
      "loss": 1.7789,
      "step": 9600
    },
    {
      "epoch": 1.7453891138101665,
      "grad_norm": 0.46167248487472534,
      "learning_rate": 0.0001853370417675449,
      "loss": 1.7816,
      "step": 9700
    },
    {
      "epoch": 1.763382816014395,
      "grad_norm": 0.4920591711997986,
      "learning_rate": 0.0001850409651953876,
      "loss": 1.781,
      "step": 9800
    },
    {
      "epoch": 1.7813765182186234,
      "grad_norm": 0.5102453827857971,
      "learning_rate": 0.0001847421706449882,
      "loss": 1.7759,
      "step": 9900
    },
    {
      "epoch": 1.799370220422852,
      "grad_norm": 0.4605036675930023,
      "learning_rate": 0.000184440667666063,
      "loss": 1.7776,
      "step": 10000
    },
    {
      "epoch": 1.8173639226270806,
      "grad_norm": 0.5136657357215881,
      "learning_rate": 0.00018413646589489178,
      "loss": 1.7783,
      "step": 10100
    },
    {
      "epoch": 1.835357624831309,
      "grad_norm": 0.5143749117851257,
      "learning_rate": 0.00018382957505401002,
      "loss": 1.7755,
      "step": 10200
    },
    {
      "epoch": 1.8533513270355375,
      "grad_norm": 0.4615934193134308,
      "learning_rate": 0.0001835200049518979,
      "loss": 1.7743,
      "step": 10300
    },
    {
      "epoch": 1.871345029239766,
      "grad_norm": 0.46391573548316956,
      "learning_rate": 0.00018320776548266706,
      "loss": 1.7733,
      "step": 10400
    },
    {
      "epoch": 1.8893387314439947,
      "grad_norm": 0.5297400951385498,
      "learning_rate": 0.0001828928666257443,
      "loss": 1.771,
      "step": 10500
    },
    {
      "epoch": 1.9073324336482231,
      "grad_norm": 0.5306834578514099,
      "learning_rate": 0.0001825753184455525,
      "loss": 1.7709,
      "step": 10600
    },
    {
      "epoch": 1.9253261358524516,
      "grad_norm": 0.4860871732234955,
      "learning_rate": 0.00018225513109118918,
      "loss": 1.7722,
      "step": 10700
    },
    {
      "epoch": 1.9433198380566803,
      "grad_norm": 0.4498753249645233,
      "learning_rate": 0.00018193231479610194,
      "loss": 1.7692,
      "step": 10800
    },
    {
      "epoch": 1.9613135402609085,
      "grad_norm": 0.486202210187912,
      "learning_rate": 0.00018160687987776148,
      "loss": 1.7669,
      "step": 10900
    },
    {
      "epoch": 1.9793072424651372,
      "grad_norm": 0.4862757623195648,
      "learning_rate": 0.0001812788367373318,
      "loss": 1.7661,
      "step": 11000
    },
    {
      "epoch": 1.9973009446693657,
      "grad_norm": 0.47103938460350037,
      "learning_rate": 0.0001809481958593378,
      "loss": 1.7622,
      "step": 11100
    },
    {
      "epoch": 2.015294646873594,
      "grad_norm": 0.4842587113380432,
      "learning_rate": 0.00018061496781133024,
      "loss": 1.7591,
      "step": 11200
    },
    {
      "epoch": 2.033288349077823,
      "grad_norm": 0.5269484519958496,
      "learning_rate": 0.00018027916324354787,
      "loss": 1.7557,
      "step": 11300
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 0.494080513715744,
      "learning_rate": 0.0001799407928885771,
      "loss": 1.7563,
      "step": 11400
    },
    {
      "epoch": 2.06927575348628,
      "grad_norm": 0.49880096316337585,
      "learning_rate": 0.00017959986756100902,
      "loss": 1.7534,
      "step": 11500
    },
    {
      "epoch": 2.0872694556905085,
      "grad_norm": 0.46329542994499207,
      "learning_rate": 0.00017925639815709365,
      "loss": 1.7523,
      "step": 11600
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.505963921546936,
      "learning_rate": 0.00017891039565439185,
      "loss": 1.7523,
      "step": 11700
    },
    {
      "epoch": 2.1232568600989654,
      "grad_norm": 0.4737144410610199,
      "learning_rate": 0.0001785618711114243,
      "loss": 1.7541,
      "step": 11800
    },
    {
      "epoch": 2.1412505623031937,
      "grad_norm": 0.4570567309856415,
      "learning_rate": 0.00017821083566731813,
      "loss": 1.7502,
      "step": 11900
    },
    {
      "epoch": 2.1592442645074224,
      "grad_norm": 0.4214823246002197,
      "learning_rate": 0.000177857300541451,
      "loss": 1.7501,
      "step": 12000
    },
    {
      "epoch": 2.177237966711651,
      "grad_norm": 0.5201253890991211,
      "learning_rate": 0.00017750127703309226,
      "loss": 1.7516,
      "step": 12100
    },
    {
      "epoch": 2.1952316689158793,
      "grad_norm": 0.4253701865673065,
      "learning_rate": 0.0001771427765210422,
      "loss": 1.7477,
      "step": 12200
    },
    {
      "epoch": 2.213225371120108,
      "grad_norm": 0.47426143288612366,
      "learning_rate": 0.0001767818104632679,
      "loss": 1.749,
      "step": 12300
    },
    {
      "epoch": 2.2312190733243367,
      "grad_norm": 0.42595574259757996,
      "learning_rate": 0.00017641839039653754,
      "loss": 1.746,
      "step": 12400
    },
    {
      "epoch": 2.249212775528565,
      "grad_norm": 0.4628443419933319,
      "learning_rate": 0.00017605252793605124,
      "loss": 1.7475,
      "step": 12500
    },
    {
      "epoch": 2.2672064777327936,
      "grad_norm": 0.47989141941070557,
      "learning_rate": 0.0001756842347750701,
      "loss": 1.7451,
      "step": 12600
    },
    {
      "epoch": 2.2852001799370223,
      "grad_norm": 0.47096145153045654,
      "learning_rate": 0.0001753135226845423,
      "loss": 1.7447,
      "step": 12700
    },
    {
      "epoch": 2.3031938821412505,
      "grad_norm": 0.4392992854118347,
      "learning_rate": 0.00017494040351272706,
      "loss": 1.7418,
      "step": 12800
    },
    {
      "epoch": 2.3211875843454792,
      "grad_norm": 0.4259919822216034,
      "learning_rate": 0.00017456488918481578,
      "loss": 1.7407,
      "step": 12900
    },
    {
      "epoch": 2.3391812865497075,
      "grad_norm": 0.4792753756046295,
      "learning_rate": 0.00017418699170255105,
      "loss": 1.7427,
      "step": 13000
    },
    {
      "epoch": 2.357174988753936,
      "grad_norm": 0.5444419980049133,
      "learning_rate": 0.00017380672314384302,
      "loss": 1.7412,
      "step": 13100
    },
    {
      "epoch": 2.375168690958165,
      "grad_norm": 0.4216329753398895,
      "learning_rate": 0.00017342409566238335,
      "loss": 1.7431,
      "step": 13200
    },
    {
      "epoch": 2.393162393162393,
      "grad_norm": 0.44661518931388855,
      "learning_rate": 0.00017303912148725675,
      "loss": 1.7422,
      "step": 13300
    },
    {
      "epoch": 2.411156095366622,
      "grad_norm": 0.44572216272354126,
      "learning_rate": 0.00017265181292255017,
      "loss": 1.7377,
      "step": 13400
    },
    {
      "epoch": 2.42914979757085,
      "grad_norm": 0.5767651796340942,
      "learning_rate": 0.0001722621823469596,
      "loss": 1.7412,
      "step": 13500
    },
    {
      "epoch": 2.4471434997750787,
      "grad_norm": 0.4501521587371826,
      "learning_rate": 0.00017187024221339433,
      "loss": 1.7378,
      "step": 13600
    },
    {
      "epoch": 2.4651372019793074,
      "grad_norm": 0.5210116505622864,
      "learning_rate": 0.00017147600504857904,
      "loss": 1.7385,
      "step": 13700
    },
    {
      "epoch": 2.4831309041835357,
      "grad_norm": 0.4316433072090149,
      "learning_rate": 0.0001710794834526533,
      "loss": 1.741,
      "step": 13800
    },
    {
      "epoch": 2.5011246063877643,
      "grad_norm": 0.4332631528377533,
      "learning_rate": 0.00017068069009876908,
      "loss": 1.7388,
      "step": 13900
    },
    {
      "epoch": 2.5191183085919926,
      "grad_norm": 0.46875324845314026,
      "learning_rate": 0.0001702796377326855,
      "loss": 1.7359,
      "step": 14000
    },
    {
      "epoch": 2.5371120107962213,
      "grad_norm": 0.5095296502113342,
      "learning_rate": 0.00016987633917236154,
      "loss": 1.7354,
      "step": 14100
    },
    {
      "epoch": 2.55510571300045,
      "grad_norm": 0.4172675907611847,
      "learning_rate": 0.00016947080730754638,
      "loss": 1.7323,
      "step": 14200
    },
    {
      "epoch": 2.573099415204678,
      "grad_norm": 0.47139522433280945,
      "learning_rate": 0.00016906305509936748,
      "loss": 1.7369,
      "step": 14300
    },
    {
      "epoch": 2.591093117408907,
      "grad_norm": 0.402788907289505,
      "learning_rate": 0.0001686530955799162,
      "loss": 1.7346,
      "step": 14400
    },
    {
      "epoch": 2.609086819613135,
      "grad_norm": 0.46845340728759766,
      "learning_rate": 0.00016824094185183136,
      "loss": 1.7315,
      "step": 14500
    },
    {
      "epoch": 2.627080521817364,
      "grad_norm": 0.4502786695957184,
      "learning_rate": 0.0001678266070878805,
      "loss": 1.734,
      "step": 14600
    },
    {
      "epoch": 2.6450742240215925,
      "grad_norm": 0.42600762844085693,
      "learning_rate": 0.00016741010453053887,
      "loss": 1.7311,
      "step": 14700
    },
    {
      "epoch": 2.6630679262258212,
      "grad_norm": 0.44151708483695984,
      "learning_rate": 0.00016699144749156606,
      "loss": 1.7332,
      "step": 14800
    },
    {
      "epoch": 2.6810616284300495,
      "grad_norm": 0.41687679290771484,
      "learning_rate": 0.00016657064935158072,
      "loss": 1.7335,
      "step": 14900
    },
    {
      "epoch": 2.699055330634278,
      "grad_norm": 0.4687259793281555,
      "learning_rate": 0.00016614772355963284,
      "loss": 1.7293,
      "step": 15000
    },
    {
      "epoch": 2.7170490328385064,
      "grad_norm": 0.4718734920024872,
      "learning_rate": 0.0001657226836327738,
      "loss": 1.7247,
      "step": 15100
    },
    {
      "epoch": 2.735042735042735,
      "grad_norm": 0.43581366539001465,
      "learning_rate": 0.0001652955431556245,
      "loss": 1.7283,
      "step": 15200
    },
    {
      "epoch": 2.753036437246964,
      "grad_norm": 0.44965681433677673,
      "learning_rate": 0.00016486631577994115,
      "loss": 1.7259,
      "step": 15300
    },
    {
      "epoch": 2.771030139451192,
      "grad_norm": 0.434414267539978,
      "learning_rate": 0.00016443501522417893,
      "loss": 1.7279,
      "step": 15400
    },
    {
      "epoch": 2.7890238416554207,
      "grad_norm": 0.4445512592792511,
      "learning_rate": 0.0001640016552730535,
      "loss": 1.7243,
      "step": 15500
    },
    {
      "epoch": 2.807017543859649,
      "grad_norm": 0.4368148148059845,
      "learning_rate": 0.00016356624977710048,
      "loss": 1.7277,
      "step": 15600
    },
    {
      "epoch": 2.8250112460638777,
      "grad_norm": 0.4434468150138855,
      "learning_rate": 0.00016312881265223277,
      "loss": 1.7225,
      "step": 15700
    },
    {
      "epoch": 2.8430049482681063,
      "grad_norm": 0.5003459453582764,
      "learning_rate": 0.0001626893578792958,
      "loss": 1.724,
      "step": 15800
    },
    {
      "epoch": 2.8609986504723346,
      "grad_norm": 0.42663058638572693,
      "learning_rate": 0.00016224789950362062,
      "loss": 1.7244,
      "step": 15900
    },
    {
      "epoch": 2.8789923526765633,
      "grad_norm": 0.4794979393482208,
      "learning_rate": 0.00016180445163457507,
      "loss": 1.7202,
      "step": 16000
    },
    {
      "epoch": 2.8969860548807915,
      "grad_norm": 0.43959230184555054,
      "learning_rate": 0.00016135902844511283,
      "loss": 1.7209,
      "step": 16100
    },
    {
      "epoch": 2.91497975708502,
      "grad_norm": 0.4423949122428894,
      "learning_rate": 0.00016091164417132044,
      "loss": 1.718,
      "step": 16200
    },
    {
      "epoch": 2.932973459289249,
      "grad_norm": 0.43431124091148376,
      "learning_rate": 0.00016046231311196222,
      "loss": 1.7202,
      "step": 16300
    },
    {
      "epoch": 2.950967161493477,
      "grad_norm": 0.4082910120487213,
      "learning_rate": 0.00016001104962802337,
      "loss": 1.7203,
      "step": 16400
    },
    {
      "epoch": 2.968960863697706,
      "grad_norm": 0.4289506673812866,
      "learning_rate": 0.000159557868142251,
      "loss": 1.7182,
      "step": 16500
    },
    {
      "epoch": 2.986954565901934,
      "grad_norm": 0.4995814561843872,
      "learning_rate": 0.000159102783138693,
      "loss": 1.7192,
      "step": 16600
    },
    {
      "epoch": 3.004948268106163,
      "grad_norm": 0.4524473249912262,
      "learning_rate": 0.00015864580916223533,
      "loss": 1.7191,
      "step": 16700
    },
    {
      "epoch": 3.0229419703103915,
      "grad_norm": 0.4469009041786194,
      "learning_rate": 0.000158186960818137,
      "loss": 1.7121,
      "step": 16800
    },
    {
      "epoch": 3.0409356725146197,
      "grad_norm": 0.4151134490966797,
      "learning_rate": 0.0001577262527715634,
      "loss": 1.7068,
      "step": 16900
    },
    {
      "epoch": 3.0589293747188484,
      "grad_norm": 0.41596224904060364,
      "learning_rate": 0.00015726369974711744,
      "loss": 1.7044,
      "step": 17000
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.463346391916275,
      "learning_rate": 0.00015679931652836908,
      "loss": 1.7076,
      "step": 17100
    },
    {
      "epoch": 3.0949167791273053,
      "grad_norm": 0.4446697533130646,
      "learning_rate": 0.00015633311795738272,
      "loss": 1.7094,
      "step": 17200
    },
    {
      "epoch": 3.112910481331534,
      "grad_norm": 0.440903902053833,
      "learning_rate": 0.00015586511893424292,
      "loss": 1.7074,
      "step": 17300
    },
    {
      "epoch": 3.1309041835357623,
      "grad_norm": 0.4247521460056305,
      "learning_rate": 0.00015539533441657815,
      "loss": 1.7042,
      "step": 17400
    },
    {
      "epoch": 3.148897885739991,
      "grad_norm": 0.40846145153045654,
      "learning_rate": 0.0001549237794190828,
      "loss": 1.7075,
      "step": 17500
    },
    {
      "epoch": 3.1668915879442197,
      "grad_norm": 0.4158206880092621,
      "learning_rate": 0.0001544504690130371,
      "loss": 1.7049,
      "step": 17600
    },
    {
      "epoch": 3.184885290148448,
      "grad_norm": 0.4041338562965393,
      "learning_rate": 0.00015397541832582563,
      "loss": 1.7065,
      "step": 17700
    },
    {
      "epoch": 3.2028789923526766,
      "grad_norm": 0.45506492257118225,
      "learning_rate": 0.00015349864254045377,
      "loss": 1.704,
      "step": 17800
    },
    {
      "epoch": 3.2208726945569053,
      "grad_norm": 0.4080885946750641,
      "learning_rate": 0.00015302015689506245,
      "loss": 1.7049,
      "step": 17900
    },
    {
      "epoch": 3.2388663967611335,
      "grad_norm": 0.45811301469802856,
      "learning_rate": 0.00015253997668244107,
      "loss": 1.702,
      "step": 18000
    },
    {
      "epoch": 3.256860098965362,
      "grad_norm": 0.495350182056427,
      "learning_rate": 0.00015205811724953883,
      "loss": 1.7066,
      "step": 18100
    },
    {
      "epoch": 3.2748538011695905,
      "grad_norm": 0.44696733355522156,
      "learning_rate": 0.0001515745939969741,
      "loss": 1.7035,
      "step": 18200
    },
    {
      "epoch": 3.292847503373819,
      "grad_norm": 0.407737135887146,
      "learning_rate": 0.00015108942237854238,
      "loss": 1.7066,
      "step": 18300
    },
    {
      "epoch": 3.310841205578048,
      "grad_norm": 0.4729158282279968,
      "learning_rate": 0.00015060261790072219,
      "loss": 1.7046,
      "step": 18400
    },
    {
      "epoch": 3.328834907782276,
      "grad_norm": 0.44649165868759155,
      "learning_rate": 0.00015011419612217955,
      "loss": 1.6987,
      "step": 18500
    },
    {
      "epoch": 3.3468286099865048,
      "grad_norm": 0.4668436050415039,
      "learning_rate": 0.00014962417265327083,
      "loss": 1.6988,
      "step": 18600
    },
    {
      "epoch": 3.364822312190733,
      "grad_norm": 0.45177021622657776,
      "learning_rate": 0.0001491325631555436,
      "loss": 1.7011,
      "step": 18700
    },
    {
      "epoch": 3.3828160143949617,
      "grad_norm": 0.4332045316696167,
      "learning_rate": 0.00014863938334123627,
      "loss": 1.703,
      "step": 18800
    },
    {
      "epoch": 3.4008097165991904,
      "grad_norm": 0.4473513960838318,
      "learning_rate": 0.00014814464897277584,
      "loss": 1.6966,
      "step": 18900
    },
    {
      "epoch": 3.4188034188034186,
      "grad_norm": 0.4659256935119629,
      "learning_rate": 0.00014764837586227412,
      "loss": 1.7004,
      "step": 19000
    },
    {
      "epoch": 3.4367971210076473,
      "grad_norm": 0.4262411892414093,
      "learning_rate": 0.00014715057987102232,
      "loss": 1.6984,
      "step": 19100
    },
    {
      "epoch": 3.454790823211876,
      "grad_norm": 0.4137357771396637,
      "learning_rate": 0.0001466512769089842,
      "loss": 1.6968,
      "step": 19200
    },
    {
      "epoch": 3.4727845254161043,
      "grad_norm": 0.41675588488578796,
      "learning_rate": 0.00014615048293428753,
      "loss": 1.6979,
      "step": 19300
    },
    {
      "epoch": 3.490778227620333,
      "grad_norm": 0.43550777435302734,
      "learning_rate": 0.00014564821395271398,
      "loss": 1.6985,
      "step": 19400
    },
    {
      "epoch": 3.5087719298245617,
      "grad_norm": 0.47555726766586304,
      "learning_rate": 0.00014514448601718778,
      "loss": 1.7008,
      "step": 19500
    },
    {
      "epoch": 3.52676563202879,
      "grad_norm": 0.38615965843200684,
      "learning_rate": 0.0001446393152272624,
      "loss": 1.6982,
      "step": 19600
    },
    {
      "epoch": 3.5447593342330186,
      "grad_norm": 0.4365931749343872,
      "learning_rate": 0.0001441327177286061,
      "loss": 1.6942,
      "step": 19700
    },
    {
      "epoch": 3.562753036437247,
      "grad_norm": 0.45590740442276,
      "learning_rate": 0.00014362470971248593,
      "loss": 1.6959,
      "step": 19800
    },
    {
      "epoch": 3.5807467386414755,
      "grad_norm": 0.44824790954589844,
      "learning_rate": 0.0001431153074152503,
      "loss": 1.6964,
      "step": 19900
    },
    {
      "epoch": 3.598740440845704,
      "grad_norm": 0.42476677894592285,
      "learning_rate": 0.00014260452711780988,
      "loss": 1.696,
      "step": 20000
    },
    {
      "epoch": 3.6167341430499325,
      "grad_norm": 0.41573646664619446,
      "learning_rate": 0.00014209238514511743,
      "loss": 1.6908,
      "step": 20100
    },
    {
      "epoch": 3.634727845254161,
      "grad_norm": 0.3868662714958191,
      "learning_rate": 0.00014157889786564577,
      "loss": 1.6943,
      "step": 20200
    },
    {
      "epoch": 3.6527215474583894,
      "grad_norm": 0.4080283045768738,
      "learning_rate": 0.00014106408169086508,
      "loss": 1.6923,
      "step": 20300
    },
    {
      "epoch": 3.670715249662618,
      "grad_norm": 0.42417627573013306,
      "learning_rate": 0.00014054795307471795,
      "loss": 1.6918,
      "step": 20400
    },
    {
      "epoch": 3.6887089518668468,
      "grad_norm": 0.4077794551849365,
      "learning_rate": 0.00014003052851309364,
      "loss": 1.6929,
      "step": 20500
    },
    {
      "epoch": 3.706702654071075,
      "grad_norm": 0.41543957591056824,
      "learning_rate": 0.00013951182454330097,
      "loss": 1.6932,
      "step": 20600
    },
    {
      "epoch": 3.7246963562753037,
      "grad_norm": 0.41989877820014954,
      "learning_rate": 0.00013899185774353962,
      "loss": 1.692,
      "step": 20700
    },
    {
      "epoch": 3.742690058479532,
      "grad_norm": 0.40842077136039734,
      "learning_rate": 0.0001384706447323704,
      "loss": 1.6932,
      "step": 20800
    },
    {
      "epoch": 3.7606837606837606,
      "grad_norm": 0.4061272144317627,
      "learning_rate": 0.000137948202168184,
      "loss": 1.6893,
      "step": 20900
    },
    {
      "epoch": 3.7786774628879893,
      "grad_norm": 0.43189430236816406,
      "learning_rate": 0.00013742454674866861,
      "loss": 1.6908,
      "step": 21000
    },
    {
      "epoch": 3.7966711650922176,
      "grad_norm": 0.4213446378707886,
      "learning_rate": 0.00013689969521027631,
      "loss": 1.6921,
      "step": 21100
    },
    {
      "epoch": 3.8146648672964463,
      "grad_norm": 0.4384268522262573,
      "learning_rate": 0.00013637366432768807,
      "loss": 1.6904,
      "step": 21200
    },
    {
      "epoch": 3.8326585695006745,
      "grad_norm": 0.4079883098602295,
      "learning_rate": 0.00013584647091327768,
      "loss": 1.6929,
      "step": 21300
    },
    {
      "epoch": 3.850652271704903,
      "grad_norm": 0.4691930413246155,
      "learning_rate": 0.00013531813181657433,
      "loss": 1.6909,
      "step": 21400
    },
    {
      "epoch": 3.868645973909132,
      "grad_norm": 0.46457308530807495,
      "learning_rate": 0.00013478866392372426,
      "loss": 1.6878,
      "step": 21500
    },
    {
      "epoch": 3.8866396761133606,
      "grad_norm": 0.42705491185188293,
      "learning_rate": 0.00013425808415695086,
      "loss": 1.6916,
      "step": 21600
    },
    {
      "epoch": 3.904633378317589,
      "grad_norm": 0.43378594517707825,
      "learning_rate": 0.00013372640947401397,
      "loss": 1.6838,
      "step": 21700
    },
    {
      "epoch": 3.9226270805218175,
      "grad_norm": 0.44063693284988403,
      "learning_rate": 0.00013319365686766777,
      "loss": 1.6861,
      "step": 21800
    },
    {
      "epoch": 3.9406207827260458,
      "grad_norm": 0.4288417398929596,
      "learning_rate": 0.00013265984336511782,
      "loss": 1.6863,
      "step": 21900
    },
    {
      "epoch": 3.9586144849302745,
      "grad_norm": 0.41863760352134705,
      "learning_rate": 0.00013212498602747672,
      "loss": 1.6857,
      "step": 22000
    },
    {
      "epoch": 3.976608187134503,
      "grad_norm": 0.5117529630661011,
      "learning_rate": 0.00013158910194921889,
      "loss": 1.682,
      "step": 22100
    },
    {
      "epoch": 3.9946018893387314,
      "grad_norm": 0.44178932905197144,
      "learning_rate": 0.0001310522082576343,
      "loss": 1.6884,
      "step": 22200
    },
    {
      "epoch": 4.01259559154296,
      "grad_norm": 0.4481196701526642,
      "learning_rate": 0.0001305143221122809,
      "loss": 1.6742,
      "step": 22300
    },
    {
      "epoch": 4.030589293747188,
      "grad_norm": 0.41102561354637146,
      "learning_rate": 0.00012997546070443624,
      "loss": 1.6698,
      "step": 22400
    },
    {
      "epoch": 4.048582995951417,
      "grad_norm": 0.40564003586769104,
      "learning_rate": 0.00012943564125654817,
      "loss": 1.6775,
      "step": 22500
    },
    {
      "epoch": 4.066576698155646,
      "grad_norm": 0.4277286231517792,
      "learning_rate": 0.00012889488102168413,
      "loss": 1.6735,
      "step": 22600
    },
    {
      "epoch": 4.084570400359874,
      "grad_norm": 0.39816975593566895,
      "learning_rate": 0.00012835319728298004,
      "loss": 1.6713,
      "step": 22700
    },
    {
      "epoch": 4.102564102564102,
      "grad_norm": 0.4354430139064789,
      "learning_rate": 0.00012781060735308762,
      "loss": 1.6736,
      "step": 22800
    },
    {
      "epoch": 4.120557804768331,
      "grad_norm": 0.41760575771331787,
      "learning_rate": 0.00012726712857362115,
      "loss": 1.6781,
      "step": 22900
    },
    {
      "epoch": 4.13855150697256,
      "grad_norm": 0.42391499876976013,
      "learning_rate": 0.00012672277831460348,
      "loss": 1.6774,
      "step": 23000
    },
    {
      "epoch": 4.156545209176788,
      "grad_norm": 0.44339197874069214,
      "learning_rate": 0.00012617757397391047,
      "loss": 1.674,
      "step": 23100
    },
    {
      "epoch": 4.174538911381017,
      "grad_norm": 0.4327433705329895,
      "learning_rate": 0.00012563153297671516,
      "loss": 1.6747,
      "step": 23200
    },
    {
      "epoch": 4.192532613585245,
      "grad_norm": 0.44137904047966003,
      "learning_rate": 0.00012508467277493087,
      "loss": 1.6748,
      "step": 23300
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 0.40832895040512085,
      "learning_rate": 0.00012453701084665325,
      "loss": 1.6749,
      "step": 23400
    },
    {
      "epoch": 4.228520017993702,
      "grad_norm": 0.41284501552581787,
      "learning_rate": 0.00012398856469560197,
      "loss": 1.673,
      "step": 23500
    },
    {
      "epoch": 4.246513720197931,
      "grad_norm": 0.46542641520500183,
      "learning_rate": 0.00012343935185056085,
      "loss": 1.6762,
      "step": 23600
    },
    {
      "epoch": 4.2645074224021595,
      "grad_norm": 0.4770393371582031,
      "learning_rate": 0.00012288938986481805,
      "loss": 1.6686,
      "step": 23700
    },
    {
      "epoch": 4.282501124606387,
      "grad_norm": 0.3989291787147522,
      "learning_rate": 0.00012233869631560486,
      "loss": 1.673,
      "step": 23800
    },
    {
      "epoch": 4.300494826810616,
      "grad_norm": 0.41163671016693115,
      "learning_rate": 0.00012178728880353383,
      "loss": 1.6724,
      "step": 23900
    },
    {
      "epoch": 4.318488529014845,
      "grad_norm": 0.5056664347648621,
      "learning_rate": 0.00012123518495203647,
      "loss": 1.6732,
      "step": 24000
    },
    {
      "epoch": 4.336482231219073,
      "grad_norm": 0.42300844192504883,
      "learning_rate": 0.00012068240240679973,
      "loss": 1.6714,
      "step": 24100
    },
    {
      "epoch": 4.354475933423302,
      "grad_norm": 0.40696924924850464,
      "learning_rate": 0.00012012895883520228,
      "loss": 1.6723,
      "step": 24200
    },
    {
      "epoch": 4.372469635627531,
      "grad_norm": 0.4176558256149292,
      "learning_rate": 0.00011957487192574968,
      "loss": 1.6704,
      "step": 24300
    },
    {
      "epoch": 4.390463337831759,
      "grad_norm": 0.4485310912132263,
      "learning_rate": 0.0001190201593875091,
      "loss": 1.6655,
      "step": 24400
    },
    {
      "epoch": 4.408457040035987,
      "grad_norm": 0.4122594892978668,
      "learning_rate": 0.00011846483894954325,
      "loss": 1.6661,
      "step": 24500
    },
    {
      "epoch": 4.426450742240216,
      "grad_norm": 0.4259756803512573,
      "learning_rate": 0.00011790892836034393,
      "loss": 1.6691,
      "step": 24600
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.430454820394516,
      "learning_rate": 0.00011735244538726456,
      "loss": 1.6715,
      "step": 24700
    },
    {
      "epoch": 4.462438146648673,
      "grad_norm": 0.4349392056465149,
      "learning_rate": 0.00011679540781595239,
      "loss": 1.6683,
      "step": 24800
    },
    {
      "epoch": 4.480431848852901,
      "grad_norm": 0.4135403037071228,
      "learning_rate": 0.00011623783344978022,
      "loss": 1.6724,
      "step": 24900
    },
    {
      "epoch": 4.49842555105713,
      "grad_norm": 0.4166470170021057,
      "learning_rate": 0.00011567974010927709,
      "loss": 1.6696,
      "step": 25000
    },
    {
      "epoch": 4.5164192532613585,
      "grad_norm": 0.4092239737510681,
      "learning_rate": 0.00011512114563155896,
      "loss": 1.6724,
      "step": 25100
    },
    {
      "epoch": 4.534412955465587,
      "grad_norm": 0.4200276732444763,
      "learning_rate": 0.00011456206786975857,
      "loss": 1.6663,
      "step": 25200
    },
    {
      "epoch": 4.552406657669816,
      "grad_norm": 0.3942035734653473,
      "learning_rate": 0.00011400252469245471,
      "loss": 1.6683,
      "step": 25300
    },
    {
      "epoch": 4.570400359874045,
      "grad_norm": 0.4089065492153168,
      "learning_rate": 0.00011344253398310134,
      "loss": 1.6702,
      "step": 25400
    },
    {
      "epoch": 4.588394062078272,
      "grad_norm": 0.4122889041900635,
      "learning_rate": 0.00011288211363945582,
      "loss": 1.6682,
      "step": 25500
    },
    {
      "epoch": 4.606387764282501,
      "grad_norm": 0.41571950912475586,
      "learning_rate": 0.00011232128157300703,
      "loss": 1.6674,
      "step": 25600
    },
    {
      "epoch": 4.62438146648673,
      "grad_norm": 0.42701444029808044,
      "learning_rate": 0.00011176005570840282,
      "loss": 1.6693,
      "step": 25700
    },
    {
      "epoch": 4.6423751686909585,
      "grad_norm": 0.462789922952652,
      "learning_rate": 0.00011119845398287712,
      "loss": 1.6642,
      "step": 25800
    },
    {
      "epoch": 4.660368870895187,
      "grad_norm": 0.41883477568626404,
      "learning_rate": 0.00011063649434567673,
      "loss": 1.6658,
      "step": 25900
    },
    {
      "epoch": 4.678362573099415,
      "grad_norm": 0.42801153659820557,
      "learning_rate": 0.00011007419475748759,
      "loss": 1.6673,
      "step": 26000
    },
    {
      "epoch": 4.696356275303644,
      "grad_norm": 0.438374787569046,
      "learning_rate": 0.00010951157318986072,
      "loss": 1.6664,
      "step": 26100
    },
    {
      "epoch": 4.714349977507872,
      "grad_norm": 0.4250866770744324,
      "learning_rate": 0.0001089486476246379,
      "loss": 1.6654,
      "step": 26200
    },
    {
      "epoch": 4.732343679712101,
      "grad_norm": 0.4867174029350281,
      "learning_rate": 0.0001083854360533769,
      "loss": 1.6665,
      "step": 26300
    },
    {
      "epoch": 4.75033738191633,
      "grad_norm": 0.39808768033981323,
      "learning_rate": 0.00010782195647677643,
      "loss": 1.6642,
      "step": 26400
    },
    {
      "epoch": 4.7683310841205575,
      "grad_norm": 0.4050814211368561,
      "learning_rate": 0.00010725822690410097,
      "loss": 1.664,
      "step": 26500
    },
    {
      "epoch": 4.786324786324786,
      "grad_norm": 0.38350623846054077,
      "learning_rate": 0.00010669426535260498,
      "loss": 1.6648,
      "step": 26600
    },
    {
      "epoch": 4.804318488529015,
      "grad_norm": 0.5214110612869263,
      "learning_rate": 0.00010613008984695723,
      "loss": 1.6651,
      "step": 26700
    },
    {
      "epoch": 4.822312190733244,
      "grad_norm": 0.4276442527770996,
      "learning_rate": 0.00010556571841866453,
      "loss": 1.6659,
      "step": 26800
    },
    {
      "epoch": 4.840305892937472,
      "grad_norm": 0.39488840103149414,
      "learning_rate": 0.00010500116910549569,
      "loss": 1.6603,
      "step": 26900
    },
    {
      "epoch": 4.8582995951417,
      "grad_norm": 0.39707842469215393,
      "learning_rate": 0.00010443645995090477,
      "loss": 1.6641,
      "step": 27000
    },
    {
      "epoch": 4.876293297345929,
      "grad_norm": 0.425191193819046,
      "learning_rate": 0.00010387160900345447,
      "loss": 1.6621,
      "step": 27100
    },
    {
      "epoch": 4.8942869995501574,
      "grad_norm": 0.40550509095191956,
      "learning_rate": 0.00010330663431623935,
      "loss": 1.6594,
      "step": 27200
    },
    {
      "epoch": 4.912280701754386,
      "grad_norm": 0.3823317885398865,
      "learning_rate": 0.0001027415539463088,
      "loss": 1.657,
      "step": 27300
    },
    {
      "epoch": 4.930274403958615,
      "grad_norm": 0.38950416445732117,
      "learning_rate": 0.00010217638595408985,
      "loss": 1.6588,
      "step": 27400
    },
    {
      "epoch": 4.948268106162843,
      "grad_norm": 0.390212744474411,
      "learning_rate": 0.00010161114840281011,
      "loss": 1.6602,
      "step": 27500
    },
    {
      "epoch": 4.966261808367071,
      "grad_norm": 0.4216185510158539,
      "learning_rate": 0.00010104585935792025,
      "loss": 1.6618,
      "step": 27600
    },
    {
      "epoch": 4.9842555105713,
      "grad_norm": 0.3804248869419098,
      "learning_rate": 0.00010048053688651681,
      "loss": 1.6599,
      "step": 27700
    },
    {
      "epoch": 5.002249212775529,
      "grad_norm": 0.39625614881515503,
      "learning_rate": 9.991519905676464e-05,
      "loss": 1.6571,
      "step": 27800
    },
    {
      "epoch": 5.020242914979757,
      "grad_norm": 0.42174607515335083,
      "learning_rate": 9.934986393731939e-05,
      "loss": 1.65,
      "step": 27900
    },
    {
      "epoch": 5.038236617183985,
      "grad_norm": 0.4500800371170044,
      "learning_rate": 9.878454959675021e-05,
      "loss": 1.6512,
      "step": 28000
    },
    {
      "epoch": 5.056230319388214,
      "grad_norm": 0.3868197798728943,
      "learning_rate": 9.821927410296197e-05,
      "loss": 1.649,
      "step": 28100
    },
    {
      "epoch": 5.074224021592443,
      "grad_norm": 0.4450388252735138,
      "learning_rate": 9.765405552261812e-05,
      "loss": 1.6459,
      "step": 28200
    },
    {
      "epoch": 5.092217723796671,
      "grad_norm": 0.3874165713787079,
      "learning_rate": 9.70889119205631e-05,
      "loss": 1.651,
      "step": 28300
    },
    {
      "epoch": 5.1102114260009,
      "grad_norm": 0.3858521580696106,
      "learning_rate": 9.652386135924483e-05,
      "loss": 1.6514,
      "step": 28400
    },
    {
      "epoch": 5.128205128205128,
      "grad_norm": 0.4174162745475769,
      "learning_rate": 9.595892189813775e-05,
      "loss": 1.6521,
      "step": 28500
    },
    {
      "epoch": 5.146198830409356,
      "grad_norm": 0.48979848623275757,
      "learning_rate": 9.539411159316536e-05,
      "loss": 1.6503,
      "step": 28600
    },
    {
      "epoch": 5.164192532613585,
      "grad_norm": 0.45025646686553955,
      "learning_rate": 9.482944849612327e-05,
      "loss": 1.6472,
      "step": 28700
    },
    {
      "epoch": 5.182186234817814,
      "grad_norm": 0.40896493196487427,
      "learning_rate": 9.426495065410213e-05,
      "loss": 1.6508,
      "step": 28800
    },
    {
      "epoch": 5.2001799370220425,
      "grad_norm": 0.4034348428249359,
      "learning_rate": 9.370063610891096e-05,
      "loss": 1.6479,
      "step": 28900
    },
    {
      "epoch": 5.218173639226271,
      "grad_norm": 0.47696614265441895,
      "learning_rate": 9.313652289650055e-05,
      "loss": 1.6456,
      "step": 29000
    },
    {
      "epoch": 5.236167341430499,
      "grad_norm": 0.4468405842781067,
      "learning_rate": 9.25726290463867e-05,
      "loss": 1.6463,
      "step": 29100
    },
    {
      "epoch": 5.254161043634728,
      "grad_norm": 0.40145930647850037,
      "learning_rate": 9.200897258107441e-05,
      "loss": 1.6467,
      "step": 29200
    },
    {
      "epoch": 5.272154745838956,
      "grad_norm": 0.44140148162841797,
      "learning_rate": 9.144557151548164e-05,
      "loss": 1.6503,
      "step": 29300
    },
    {
      "epoch": 5.290148448043185,
      "grad_norm": 0.409736305475235,
      "learning_rate": 9.088244385636349e-05,
      "loss": 1.6502,
      "step": 29400
    },
    {
      "epoch": 5.308142150247414,
      "grad_norm": 0.4006206691265106,
      "learning_rate": 9.031960760173683e-05,
      "loss": 1.6473,
      "step": 29500
    },
    {
      "epoch": 5.326135852451642,
      "grad_norm": 0.4051240086555481,
      "learning_rate": 8.975708074030505e-05,
      "loss": 1.6479,
      "step": 29600
    },
    {
      "epoch": 5.34412955465587,
      "grad_norm": 0.3976549804210663,
      "learning_rate": 8.919488125088294e-05,
      "loss": 1.6482,
      "step": 29700
    },
    {
      "epoch": 5.362123256860099,
      "grad_norm": 0.3978251814842224,
      "learning_rate": 8.863302710182232e-05,
      "loss": 1.648,
      "step": 29800
    },
    {
      "epoch": 5.380116959064328,
      "grad_norm": 0.42280900478363037,
      "learning_rate": 8.807153625043768e-05,
      "loss": 1.6478,
      "step": 29900
    },
    {
      "epoch": 5.398110661268556,
      "grad_norm": 0.42494717240333557,
      "learning_rate": 8.75104266424321e-05,
      "loss": 1.6477,
      "step": 30000
    },
    {
      "epoch": 5.416104363472784,
      "grad_norm": 0.4201543927192688,
      "learning_rate": 8.69497162113239e-05,
      "loss": 1.6445,
      "step": 30100
    },
    {
      "epoch": 5.434098065677013,
      "grad_norm": 0.4036836624145508,
      "learning_rate": 8.63894228778734e-05,
      "loss": 1.6483,
      "step": 30200
    },
    {
      "epoch": 5.4520917678812415,
      "grad_norm": 0.3901712894439697,
      "learning_rate": 8.582956454951012e-05,
      "loss": 1.6502,
      "step": 30300
    },
    {
      "epoch": 5.47008547008547,
      "grad_norm": 0.40137630701065063,
      "learning_rate": 8.527015911976039e-05,
      "loss": 1.6406,
      "step": 30400
    },
    {
      "epoch": 5.488079172289699,
      "grad_norm": 0.4707901179790497,
      "learning_rate": 8.471122446767566e-05,
      "loss": 1.647,
      "step": 30500
    },
    {
      "epoch": 5.506072874493928,
      "grad_norm": 0.4268963634967804,
      "learning_rate": 8.415277845726085e-05,
      "loss": 1.6472,
      "step": 30600
    },
    {
      "epoch": 5.524066576698155,
      "grad_norm": 0.40523791313171387,
      "learning_rate": 8.359483893690352e-05,
      "loss": 1.6446,
      "step": 30700
    },
    {
      "epoch": 5.542060278902384,
      "grad_norm": 0.39692381024360657,
      "learning_rate": 8.303742373880338e-05,
      "loss": 1.6431,
      "step": 30800
    },
    {
      "epoch": 5.560053981106613,
      "grad_norm": 0.4607389569282532,
      "learning_rate": 8.248055067840248e-05,
      "loss": 1.6425,
      "step": 30900
    },
    {
      "epoch": 5.578047683310841,
      "grad_norm": 0.41905784606933594,
      "learning_rate": 8.192423755381551e-05,
      "loss": 1.6479,
      "step": 31000
    },
    {
      "epoch": 5.59604138551507,
      "grad_norm": 0.4040331542491913,
      "learning_rate": 8.136850214526134e-05,
      "loss": 1.6447,
      "step": 31100
    },
    {
      "epoch": 5.614035087719298,
      "grad_norm": 0.3965131640434265,
      "learning_rate": 8.081336221449451e-05,
      "loss": 1.6439,
      "step": 31200
    },
    {
      "epoch": 5.632028789923527,
      "grad_norm": 0.41779014468193054,
      "learning_rate": 8.025883550423755e-05,
      "loss": 1.6446,
      "step": 31300
    },
    {
      "epoch": 5.650022492127755,
      "grad_norm": 0.40812012553215027,
      "learning_rate": 7.970493973761405e-05,
      "loss": 1.6454,
      "step": 31400
    },
    {
      "epoch": 5.668016194331984,
      "grad_norm": 0.4278724789619446,
      "learning_rate": 7.915169261758212e-05,
      "loss": 1.642,
      "step": 31500
    },
    {
      "epoch": 5.686009896536213,
      "grad_norm": 0.42020660638809204,
      "learning_rate": 7.859911182636849e-05,
      "loss": 1.6436,
      "step": 31600
    },
    {
      "epoch": 5.7040035987404405,
      "grad_norm": 0.46238261461257935,
      "learning_rate": 7.80472150249036e-05,
      "loss": 1.64,
      "step": 31700
    },
    {
      "epoch": 5.721997300944669,
      "grad_norm": 0.3945958614349365,
      "learning_rate": 7.749601985225697e-05,
      "loss": 1.6426,
      "step": 31800
    },
    {
      "epoch": 5.739991003148898,
      "grad_norm": 0.40836384892463684,
      "learning_rate": 7.694554392507358e-05,
      "loss": 1.6411,
      "step": 31900
    },
    {
      "epoch": 5.757984705353127,
      "grad_norm": 0.4290982186794281,
      "learning_rate": 7.639580483701057e-05,
      "loss": 1.6412,
      "step": 32000
    },
    {
      "epoch": 5.775978407557355,
      "grad_norm": 0.38603338599205017,
      "learning_rate": 7.584682015817524e-05,
      "loss": 1.6412,
      "step": 32100
    },
    {
      "epoch": 5.793972109761583,
      "grad_norm": 0.3817940056324005,
      "learning_rate": 7.529860743456334e-05,
      "loss": 1.6413,
      "step": 32200
    },
    {
      "epoch": 5.811965811965812,
      "grad_norm": 0.401105672121048,
      "learning_rate": 7.475118418749825e-05,
      "loss": 1.6397,
      "step": 32300
    },
    {
      "epoch": 5.82995951417004,
      "grad_norm": 0.42844006419181824,
      "learning_rate": 7.420456791307109e-05,
      "loss": 1.6415,
      "step": 32400
    },
    {
      "epoch": 5.847953216374269,
      "grad_norm": 0.3875371515750885,
      "learning_rate": 7.36587760815815e-05,
      "loss": 1.6385,
      "step": 32500
    },
    {
      "epoch": 5.865946918578498,
      "grad_norm": 0.42309051752090454,
      "learning_rate": 7.311382613697917e-05,
      "loss": 1.6397,
      "step": 32600
    },
    {
      "epoch": 5.883940620782726,
      "grad_norm": 0.4562065899372101,
      "learning_rate": 7.256973549630645e-05,
      "loss": 1.6422,
      "step": 32700
    },
    {
      "epoch": 5.901934322986954,
      "grad_norm": 0.42868176102638245,
      "learning_rate": 7.202652154914169e-05,
      "loss": 1.6426,
      "step": 32800
    },
    {
      "epoch": 5.919928025191183,
      "grad_norm": 0.44123247265815735,
      "learning_rate": 7.148420165704331e-05,
      "loss": 1.6397,
      "step": 32900
    },
    {
      "epoch": 5.937921727395412,
      "grad_norm": 0.40733397006988525,
      "learning_rate": 7.094279315299506e-05,
      "loss": 1.6381,
      "step": 33000
    },
    {
      "epoch": 5.95591542959964,
      "grad_norm": 0.40964779257774353,
      "learning_rate": 7.040231334085204e-05,
      "loss": 1.6382,
      "step": 33100
    },
    {
      "epoch": 5.973909131803868,
      "grad_norm": 0.43876320123672485,
      "learning_rate": 6.986277949478743e-05,
      "loss": 1.6394,
      "step": 33200
    },
    {
      "epoch": 5.991902834008097,
      "grad_norm": 0.49204522371292114,
      "learning_rate": 6.932420885874074e-05,
      "loss": 1.6412,
      "step": 33300
    },
    {
      "epoch": 6.009896536212326,
      "grad_norm": 0.4019051194190979,
      "learning_rate": 6.878661864586644e-05,
      "loss": 1.6314,
      "step": 33400
    },
    {
      "epoch": 6.027890238416554,
      "grad_norm": 0.4516865611076355,
      "learning_rate": 6.825002603798394e-05,
      "loss": 1.6295,
      "step": 33500
    },
    {
      "epoch": 6.045883940620783,
      "grad_norm": 0.4090317487716675,
      "learning_rate": 6.771444818502822e-05,
      "loss": 1.6298,
      "step": 33600
    },
    {
      "epoch": 6.063877642825012,
      "grad_norm": 0.4081929624080658,
      "learning_rate": 6.717990220450203e-05,
      "loss": 1.6265,
      "step": 33700
    },
    {
      "epoch": 6.081871345029239,
      "grad_norm": 0.41558966040611267,
      "learning_rate": 6.664640518092862e-05,
      "loss": 1.6259,
      "step": 33800
    },
    {
      "epoch": 6.099865047233468,
      "grad_norm": 0.4258418381214142,
      "learning_rate": 6.611397416530563e-05,
      "loss": 1.6282,
      "step": 33900
    },
    {
      "epoch": 6.117858749437697,
      "grad_norm": 0.4030762314796448,
      "learning_rate": 6.558262617456033e-05,
      "loss": 1.6282,
      "step": 34000
    },
    {
      "epoch": 6.1358524516419255,
      "grad_norm": 0.3807661533355713,
      "learning_rate": 6.505237819100563e-05,
      "loss": 1.6282,
      "step": 34100
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 0.43781808018684387,
      "learning_rate": 6.452324716179718e-05,
      "loss": 1.6273,
      "step": 34200
    },
    {
      "epoch": 6.171839856050382,
      "grad_norm": 0.4090070426464081,
      "learning_rate": 6.399524999839202e-05,
      "loss": 1.6354,
      "step": 34300
    },
    {
      "epoch": 6.189833558254611,
      "grad_norm": 0.4203646183013916,
      "learning_rate": 6.34684035760079e-05,
      "loss": 1.6277,
      "step": 34400
    },
    {
      "epoch": 6.207827260458839,
      "grad_norm": 0.3807961940765381,
      "learning_rate": 6.294272473308382e-05,
      "loss": 1.6315,
      "step": 34500
    },
    {
      "epoch": 6.225820962663068,
      "grad_norm": 0.4233347773551941,
      "learning_rate": 6.241823027074213e-05,
      "loss": 1.6307,
      "step": 34600
    },
    {
      "epoch": 6.243814664867297,
      "grad_norm": 0.38825175166130066,
      "learning_rate": 6.189493695225141e-05,
      "loss": 1.6285,
      "step": 34700
    },
    {
      "epoch": 6.2618083670715246,
      "grad_norm": 0.40691614151000977,
      "learning_rate": 6.13728615024906e-05,
      "loss": 1.6271,
      "step": 34800
    },
    {
      "epoch": 6.279802069275753,
      "grad_norm": 0.3917976915836334,
      "learning_rate": 6.0852020607414686e-05,
      "loss": 1.6293,
      "step": 34900
    },
    {
      "epoch": 6.297795771479982,
      "grad_norm": 0.39886781573295593,
      "learning_rate": 6.033243091352123e-05,
      "loss": 1.6267,
      "step": 35000
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 0.4279647171497345,
      "learning_rate": 5.981410902731843e-05,
      "loss": 1.6304,
      "step": 35100
    },
    {
      "epoch": 6.333783175888439,
      "grad_norm": 0.4604890048503876,
      "learning_rate": 5.929707151479422e-05,
      "loss": 1.6295,
      "step": 35200
    },
    {
      "epoch": 6.351776878092668,
      "grad_norm": 0.38956862688064575,
      "learning_rate": 5.8781334900887016e-05,
      "loss": 1.6287,
      "step": 35300
    },
    {
      "epoch": 6.369770580296896,
      "grad_norm": 0.45218682289123535,
      "learning_rate": 5.8266915668957433e-05,
      "loss": 1.63,
      "step": 35400
    },
    {
      "epoch": 6.3877642825011245,
      "grad_norm": 0.4568408131599426,
      "learning_rate": 5.7753830260261435e-05,
      "loss": 1.6273,
      "step": 35500
    },
    {
      "epoch": 6.405757984705353,
      "grad_norm": 0.4279671907424927,
      "learning_rate": 5.724209507342496e-05,
      "loss": 1.6239,
      "step": 35600
    },
    {
      "epoch": 6.423751686909582,
      "grad_norm": 0.38656875491142273,
      "learning_rate": 5.673172646391982e-05,
      "loss": 1.6247,
      "step": 35700
    },
    {
      "epoch": 6.441745389113811,
      "grad_norm": 0.40276414155960083,
      "learning_rate": 5.622274074354075e-05,
      "loss": 1.627,
      "step": 35800
    },
    {
      "epoch": 6.459739091318038,
      "grad_norm": 0.40787655115127563,
      "learning_rate": 5.571515417988435e-05,
      "loss": 1.6264,
      "step": 35900
    },
    {
      "epoch": 6.477732793522267,
      "grad_norm": 0.3798348009586334,
      "learning_rate": 5.520898299582902e-05,
      "loss": 1.6241,
      "step": 36000
    },
    {
      "epoch": 6.495726495726496,
      "grad_norm": 0.43635323643684387,
      "learning_rate": 5.470424336901644e-05,
      "loss": 1.6234,
      "step": 36100
    },
    {
      "epoch": 6.513720197930724,
      "grad_norm": 0.425991415977478,
      "learning_rate": 5.42009514313346e-05,
      "loss": 1.6285,
      "step": 36200
    },
    {
      "epoch": 6.531713900134953,
      "grad_norm": 0.3951183557510376,
      "learning_rate": 5.3699123268402195e-05,
      "loss": 1.6256,
      "step": 36300
    },
    {
      "epoch": 6.549707602339181,
      "grad_norm": 0.3929756283760071,
      "learning_rate": 5.319877491905436e-05,
      "loss": 1.6294,
      "step": 36400
    },
    {
      "epoch": 6.56770130454341,
      "grad_norm": 0.4167487919330597,
      "learning_rate": 5.269992237483032e-05,
      "loss": 1.6287,
      "step": 36500
    },
    {
      "epoch": 6.585695006747638,
      "grad_norm": 0.39888283610343933,
      "learning_rate": 5.220258157946212e-05,
      "loss": 1.6251,
      "step": 36600
    },
    {
      "epoch": 6.603688708951867,
      "grad_norm": 0.4011279344558716,
      "learning_rate": 5.1706768428365104e-05,
      "loss": 1.6261,
      "step": 36700
    },
    {
      "epoch": 6.621682411156096,
      "grad_norm": 0.41302093863487244,
      "learning_rate": 5.121249876812977e-05,
      "loss": 1.6271,
      "step": 36800
    },
    {
      "epoch": 6.6396761133603235,
      "grad_norm": 0.40935343503952026,
      "learning_rate": 5.071978839601549e-05,
      "loss": 1.6281,
      "step": 36900
    },
    {
      "epoch": 6.657669815564552,
      "grad_norm": 0.3991980254650116,
      "learning_rate": 5.022865305944554e-05,
      "loss": 1.6275,
      "step": 37000
    },
    {
      "epoch": 6.675663517768781,
      "grad_norm": 0.40640145540237427,
      "learning_rate": 4.973910845550367e-05,
      "loss": 1.6232,
      "step": 37100
    },
    {
      "epoch": 6.6936572199730096,
      "grad_norm": 0.38927754759788513,
      "learning_rate": 4.925117023043262e-05,
      "loss": 1.6286,
      "step": 37200
    },
    {
      "epoch": 6.711650922177238,
      "grad_norm": 0.4313541650772095,
      "learning_rate": 4.8764853979133986e-05,
      "loss": 1.6264,
      "step": 37300
    },
    {
      "epoch": 6.729644624381466,
      "grad_norm": 0.3926027715206146,
      "learning_rate": 4.828017524466961e-05,
      "loss": 1.6245,
      "step": 37400
    },
    {
      "epoch": 6.747638326585695,
      "grad_norm": 0.40752291679382324,
      "learning_rate": 4.7797149517765136e-05,
      "loss": 1.6198,
      "step": 37500
    },
    {
      "epoch": 6.765632028789923,
      "grad_norm": 0.4371185004711151,
      "learning_rate": 4.731579223631466e-05,
      "loss": 1.6252,
      "step": 37600
    },
    {
      "epoch": 6.783625730994152,
      "grad_norm": 0.39649486541748047,
      "learning_rate": 4.683611878488743e-05,
      "loss": 1.6249,
      "step": 37700
    },
    {
      "epoch": 6.801619433198381,
      "grad_norm": 0.3972003757953644,
      "learning_rate": 4.635814449423611e-05,
      "loss": 1.6246,
      "step": 37800
    },
    {
      "epoch": 6.819613135402609,
      "grad_norm": 0.43168747425079346,
      "learning_rate": 4.5881884640806874e-05,
      "loss": 1.6235,
      "step": 37900
    },
    {
      "epoch": 6.837606837606837,
      "grad_norm": 0.38064566254615784,
      "learning_rate": 4.5407354446250935e-05,
      "loss": 1.6211,
      "step": 38000
    },
    {
      "epoch": 6.855600539811066,
      "grad_norm": 0.4047590494155884,
      "learning_rate": 4.493456907693834e-05,
      "loss": 1.6211,
      "step": 38100
    },
    {
      "epoch": 6.873594242015295,
      "grad_norm": 0.38640397787094116,
      "learning_rate": 4.4463543643473084e-05,
      "loss": 1.6239,
      "step": 38200
    },
    {
      "epoch": 6.891587944219523,
      "grad_norm": 0.3851824104785919,
      "learning_rate": 4.399429320021018e-05,
      "loss": 1.627,
      "step": 38300
    },
    {
      "epoch": 6.909581646423752,
      "grad_norm": 0.3916865587234497,
      "learning_rate": 4.352683274477444e-05,
      "loss": 1.6249,
      "step": 38400
    },
    {
      "epoch": 6.92757534862798,
      "grad_norm": 0.40043744444847107,
      "learning_rate": 4.306117721758131e-05,
      "loss": 1.6245,
      "step": 38500
    },
    {
      "epoch": 6.9455690508322085,
      "grad_norm": 0.3981209099292755,
      "learning_rate": 4.259734150135927e-05,
      "loss": 1.6207,
      "step": 38600
    },
    {
      "epoch": 6.963562753036437,
      "grad_norm": 0.4150641858577728,
      "learning_rate": 4.213534042067404e-05,
      "loss": 1.6199,
      "step": 38700
    },
    {
      "epoch": 6.981556455240666,
      "grad_norm": 0.39347872138023376,
      "learning_rate": 4.167518874145503e-05,
      "loss": 1.6186,
      "step": 38800
    },
    {
      "epoch": 6.999550157444895,
      "grad_norm": 0.39450961351394653,
      "learning_rate": 4.121690117052327e-05,
      "loss": 1.6206,
      "step": 38900
    },
    {
      "epoch": 7.017543859649122,
      "grad_norm": 0.3756377100944519,
      "learning_rate": 4.076049235512126e-05,
      "loss": 1.6126,
      "step": 39000
    },
    {
      "epoch": 7.035537561853351,
      "grad_norm": 0.40967506170272827,
      "learning_rate": 4.030597688244506e-05,
      "loss": 1.6114,
      "step": 39100
    },
    {
      "epoch": 7.05353126405758,
      "grad_norm": 0.39508551359176636,
      "learning_rate": 3.985336927917799e-05,
      "loss": 1.6142,
      "step": 39200
    },
    {
      "epoch": 7.0715249662618085,
      "grad_norm": 0.3995456099510193,
      "learning_rate": 3.940268401102615e-05,
      "loss": 1.6148,
      "step": 39300
    },
    {
      "epoch": 7.089518668466037,
      "grad_norm": 0.44109806418418884,
      "learning_rate": 3.895393548225641e-05,
      "loss": 1.6131,
      "step": 39400
    },
    {
      "epoch": 7.107512370670265,
      "grad_norm": 0.3855528235435486,
      "learning_rate": 3.850713803523581e-05,
      "loss": 1.6157,
      "step": 39500
    },
    {
      "epoch": 7.125506072874494,
      "grad_norm": 0.3990499675273895,
      "learning_rate": 3.8062305949973265e-05,
      "loss": 1.6092,
      "step": 39600
    },
    {
      "epoch": 7.143499775078722,
      "grad_norm": 0.4000775218009949,
      "learning_rate": 3.761945344366311e-05,
      "loss": 1.6137,
      "step": 39700
    },
    {
      "epoch": 7.161493477282951,
      "grad_norm": 0.39230018854141235,
      "learning_rate": 3.7178594670230724e-05,
      "loss": 1.6155,
      "step": 39800
    },
    {
      "epoch": 7.17948717948718,
      "grad_norm": 0.4132891595363617,
      "learning_rate": 3.6739743719880225e-05,
      "loss": 1.6134,
      "step": 39900
    },
    {
      "epoch": 7.197480881691408,
      "grad_norm": 0.41426047682762146,
      "learning_rate": 3.6302914618643956e-05,
      "loss": 1.6122,
      "step": 40000
    },
    {
      "epoch": 7.215474583895636,
      "grad_norm": 0.38532084226608276,
      "learning_rate": 3.586812132793444e-05,
      "loss": 1.6112,
      "step": 40100
    },
    {
      "epoch": 7.233468286099865,
      "grad_norm": 0.42225033044815063,
      "learning_rate": 3.543537774409801e-05,
      "loss": 1.611,
      "step": 40200
    },
    {
      "epoch": 7.251461988304094,
      "grad_norm": 0.39547160267829895,
      "learning_rate": 3.5004697697970645e-05,
      "loss": 1.6139,
      "step": 40300
    },
    {
      "epoch": 7.269455690508322,
      "grad_norm": 0.38546890020370483,
      "learning_rate": 3.4576094954436054e-05,
      "loss": 1.6166,
      "step": 40400
    },
    {
      "epoch": 7.287449392712551,
      "grad_norm": 0.462562620639801,
      "learning_rate": 3.4149583211985705e-05,
      "loss": 1.6149,
      "step": 40500
    },
    {
      "epoch": 7.305443094916779,
      "grad_norm": 0.39050498604774475,
      "learning_rate": 3.372517610228083e-05,
      "loss": 1.6123,
      "step": 40600
    },
    {
      "epoch": 7.3234367971210075,
      "grad_norm": 0.38317638635635376,
      "learning_rate": 3.3302887189717024e-05,
      "loss": 1.6147,
      "step": 40700
    },
    {
      "epoch": 7.341430499325236,
      "grad_norm": 0.40973037481307983,
      "learning_rate": 3.288272997099057e-05,
      "loss": 1.6118,
      "step": 40800
    },
    {
      "epoch": 7.359424201529465,
      "grad_norm": 0.39154553413391113,
      "learning_rate": 3.246471787466699e-05,
      "loss": 1.6139,
      "step": 40900
    },
    {
      "epoch": 7.3774179037336935,
      "grad_norm": 0.3968620300292969,
      "learning_rate": 3.204886426075205e-05,
      "loss": 1.6103,
      "step": 41000
    },
    {
      "epoch": 7.395411605937921,
      "grad_norm": 0.3875632584095001,
      "learning_rate": 3.163518242026463e-05,
      "loss": 1.6126,
      "step": 41100
    },
    {
      "epoch": 7.41340530814215,
      "grad_norm": 0.4060792624950409,
      "learning_rate": 3.1223685574812e-05,
      "loss": 1.6132,
      "step": 41200
    },
    {
      "epoch": 7.431399010346379,
      "grad_norm": 0.3819294273853302,
      "learning_rate": 3.0814386876167156e-05,
      "loss": 1.6118,
      "step": 41300
    },
    {
      "epoch": 7.449392712550607,
      "grad_norm": 0.3910393714904785,
      "learning_rate": 3.04072994058486e-05,
      "loss": 1.6113,
      "step": 41400
    },
    {
      "epoch": 7.467386414754836,
      "grad_norm": 0.38729897141456604,
      "learning_rate": 3.0002436174702176e-05,
      "loss": 1.6097,
      "step": 41500
    },
    {
      "epoch": 7.485380116959064,
      "grad_norm": 0.3801003098487854,
      "learning_rate": 2.9599810122485174e-05,
      "loss": 1.613,
      "step": 41600
    },
    {
      "epoch": 7.503373819163293,
      "grad_norm": 0.379707008600235,
      "learning_rate": 2.9199434117452885e-05,
      "loss": 1.6114,
      "step": 41700
    },
    {
      "epoch": 7.521367521367521,
      "grad_norm": 0.4001777172088623,
      "learning_rate": 2.8801320955947296e-05,
      "loss": 1.6132,
      "step": 41800
    },
    {
      "epoch": 7.53936122357175,
      "grad_norm": 0.39705732464790344,
      "learning_rate": 2.8405483361987985e-05,
      "loss": 1.6101,
      "step": 41900
    },
    {
      "epoch": 7.557354925775979,
      "grad_norm": 0.39355289936065674,
      "learning_rate": 2.8011933986865634e-05,
      "loss": 1.6107,
      "step": 42000
    },
    {
      "epoch": 7.5753486279802065,
      "grad_norm": 0.42184481024742126,
      "learning_rate": 2.762068540873759e-05,
      "loss": 1.6126,
      "step": 42100
    },
    {
      "epoch": 7.593342330184435,
      "grad_norm": 0.39544934034347534,
      "learning_rate": 2.7231750132225765e-05,
      "loss": 1.6127,
      "step": 42200
    },
    {
      "epoch": 7.611336032388664,
      "grad_norm": 0.41272395849227905,
      "learning_rate": 2.684514058801717e-05,
      "loss": 1.6112,
      "step": 42300
    },
    {
      "epoch": 7.6293297345928925,
      "grad_norm": 0.3883473873138428,
      "learning_rate": 2.646086913246655e-05,
      "loss": 1.6124,
      "step": 42400
    },
    {
      "epoch": 7.647323436797121,
      "grad_norm": 0.39075666666030884,
      "learning_rate": 2.60789480472013e-05,
      "loss": 1.6097,
      "step": 42500
    },
    {
      "epoch": 7.665317139001349,
      "grad_norm": 0.3984563946723938,
      "learning_rate": 2.5699389538729214e-05,
      "loss": 1.6093,
      "step": 42600
    },
    {
      "epoch": 7.683310841205578,
      "grad_norm": 0.4020855128765106,
      "learning_rate": 2.5322205738048176e-05,
      "loss": 1.6072,
      "step": 42700
    },
    {
      "epoch": 7.701304543409806,
      "grad_norm": 0.3782440721988678,
      "learning_rate": 2.4947408700258414e-05,
      "loss": 1.6133,
      "step": 42800
    },
    {
      "epoch": 7.719298245614035,
      "grad_norm": 0.3924615681171417,
      "learning_rate": 2.4575010404177358e-05,
      "loss": 1.6117,
      "step": 42900
    },
    {
      "epoch": 7.737291947818264,
      "grad_norm": 0.37023434042930603,
      "learning_rate": 2.4205022751956687e-05,
      "loss": 1.6098,
      "step": 43000
    },
    {
      "epoch": 7.7552856500224925,
      "grad_norm": 0.4221959710121155,
      "learning_rate": 2.3837457568701928e-05,
      "loss": 1.6105,
      "step": 43100
    },
    {
      "epoch": 7.77327935222672,
      "grad_norm": 0.37942731380462646,
      "learning_rate": 2.3472326602094563e-05,
      "loss": 1.6066,
      "step": 43200
    },
    {
      "epoch": 7.791273054430949,
      "grad_norm": 0.36606085300445557,
      "learning_rate": 2.31096415220165e-05,
      "loss": 1.6113,
      "step": 43300
    },
    {
      "epoch": 7.809266756635178,
      "grad_norm": 0.40023073554039,
      "learning_rate": 2.2749413920177188e-05,
      "loss": 1.6138,
      "step": 43400
    },
    {
      "epoch": 7.827260458839406,
      "grad_norm": 0.3875234127044678,
      "learning_rate": 2.2391655309742986e-05,
      "loss": 1.6072,
      "step": 43500
    },
    {
      "epoch": 7.845254161043635,
      "grad_norm": 0.38649049401283264,
      "learning_rate": 2.2036377124969356e-05,
      "loss": 1.6108,
      "step": 43600
    },
    {
      "epoch": 7.863247863247864,
      "grad_norm": 0.3874686658382416,
      "learning_rate": 2.1683590720835344e-05,
      "loss": 1.6106,
      "step": 43700
    },
    {
      "epoch": 7.8812415654520915,
      "grad_norm": 0.3970390856266022,
      "learning_rate": 2.13333073726806e-05,
      "loss": 1.6083,
      "step": 43800
    },
    {
      "epoch": 7.89923526765632,
      "grad_norm": 0.4100150167942047,
      "learning_rate": 2.098553827584514e-05,
      "loss": 1.6085,
      "step": 43900
    },
    {
      "epoch": 7.917228969860549,
      "grad_norm": 0.37879446148872375,
      "learning_rate": 2.064029454531148e-05,
      "loss": 1.6109,
      "step": 44000
    },
    {
      "epoch": 7.935222672064778,
      "grad_norm": 0.3792925179004669,
      "learning_rate": 2.029758721534929e-05,
      "loss": 1.6091,
      "step": 44100
    },
    {
      "epoch": 7.953216374269006,
      "grad_norm": 0.37914568185806274,
      "learning_rate": 1.9957427239162897e-05,
      "loss": 1.6052,
      "step": 44200
    },
    {
      "epoch": 7.971210076473234,
      "grad_norm": 0.4181497395038605,
      "learning_rate": 1.9619825488541153e-05,
      "loss": 1.6039,
      "step": 44300
    },
    {
      "epoch": 7.989203778677463,
      "grad_norm": 0.403664231300354,
      "learning_rate": 1.928479275350985e-05,
      "loss": 1.6118,
      "step": 44400
    },
    {
      "epoch": 8.007197480881691,
      "grad_norm": 0.3902496099472046,
      "learning_rate": 1.8952339741987036e-05,
      "loss": 1.604,
      "step": 44500
    },
    {
      "epoch": 8.02519118308592,
      "grad_norm": 0.3803662955760956,
      "learning_rate": 1.862247707944068e-05,
      "loss": 1.6012,
      "step": 44600
    },
    {
      "epoch": 8.043184885290149,
      "grad_norm": 0.3824043571949005,
      "learning_rate": 1.8295215308549107e-05,
      "loss": 1.6021,
      "step": 44700
    },
    {
      "epoch": 8.061178587494377,
      "grad_norm": 0.3808002769947052,
      "learning_rate": 1.7970564888864017e-05,
      "loss": 1.6034,
      "step": 44800
    },
    {
      "epoch": 8.079172289698606,
      "grad_norm": 0.38522595167160034,
      "learning_rate": 1.7648536196476218e-05,
      "loss": 1.6013,
      "step": 44900
    },
    {
      "epoch": 8.097165991902834,
      "grad_norm": 0.3791276216506958,
      "learning_rate": 1.732913952368401e-05,
      "loss": 1.5999,
      "step": 45000
    },
    {
      "epoch": 8.115159694107062,
      "grad_norm": 0.3909854292869568,
      "learning_rate": 1.7012385078664128e-05,
      "loss": 1.6052,
      "step": 45100
    },
    {
      "epoch": 8.133153396311291,
      "grad_norm": 0.38076987862586975,
      "learning_rate": 1.6698282985145654e-05,
      "loss": 1.6007,
      "step": 45200
    },
    {
      "epoch": 8.15114709851552,
      "grad_norm": 0.3809574246406555,
      "learning_rate": 1.638684328208634e-05,
      "loss": 1.6042,
      "step": 45300
    },
    {
      "epoch": 8.169140800719749,
      "grad_norm": 0.385321706533432,
      "learning_rate": 1.6078075923351733e-05,
      "loss": 1.5995,
      "step": 45400
    },
    {
      "epoch": 8.187134502923977,
      "grad_norm": 0.3993207514286041,
      "learning_rate": 1.577199077739715e-05,
      "loss": 1.6035,
      "step": 45500
    },
    {
      "epoch": 8.205128205128204,
      "grad_norm": 0.3995744287967682,
      "learning_rate": 1.5468597626952196e-05,
      "loss": 1.6003,
      "step": 45600
    },
    {
      "epoch": 8.223121907332434,
      "grad_norm": 0.42250069975852966,
      "learning_rate": 1.5167906168708067e-05,
      "loss": 1.6016,
      "step": 45700
    },
    {
      "epoch": 8.241115609536662,
      "grad_norm": 0.385513573884964,
      "learning_rate": 1.486992601300775e-05,
      "loss": 1.6025,
      "step": 45800
    },
    {
      "epoch": 8.259109311740891,
      "grad_norm": 0.4028950333595276,
      "learning_rate": 1.4574666683538785e-05,
      "loss": 1.6033,
      "step": 45900
    },
    {
      "epoch": 8.27710301394512,
      "grad_norm": 0.42525896430015564,
      "learning_rate": 1.4282137617028846e-05,
      "loss": 1.6018,
      "step": 46000
    },
    {
      "epoch": 8.295096716149347,
      "grad_norm": 0.39206618070602417,
      "learning_rate": 1.3992348162944258e-05,
      "loss": 1.5998,
      "step": 46100
    },
    {
      "epoch": 8.313090418353577,
      "grad_norm": 0.3834252655506134,
      "learning_rate": 1.3705307583191085e-05,
      "loss": 1.6032,
      "step": 46200
    },
    {
      "epoch": 8.331084120557804,
      "grad_norm": 0.39092206954956055,
      "learning_rate": 1.3421025051819147e-05,
      "loss": 1.5992,
      "step": 46300
    },
    {
      "epoch": 8.349077822762034,
      "grad_norm": 0.39707639813423157,
      "learning_rate": 1.3139509654728743e-05,
      "loss": 1.6021,
      "step": 46400
    },
    {
      "epoch": 8.367071524966262,
      "grad_norm": 0.4002411961555481,
      "learning_rate": 1.2860770389380384e-05,
      "loss": 1.5991,
      "step": 46500
    },
    {
      "epoch": 8.38506522717049,
      "grad_norm": 0.38362693786621094,
      "learning_rate": 1.258481616450714e-05,
      "loss": 1.6005,
      "step": 46600
    },
    {
      "epoch": 8.403058929374719,
      "grad_norm": 0.3911925256252289,
      "learning_rate": 1.2311655799829925e-05,
      "loss": 1.5999,
      "step": 46700
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 0.3713332712650299,
      "learning_rate": 1.2041298025775594e-05,
      "loss": 1.6043,
      "step": 46800
    },
    {
      "epoch": 8.439046333783176,
      "grad_norm": 0.3845612704753876,
      "learning_rate": 1.1773751483197981e-05,
      "loss": 1.6024,
      "step": 46900
    },
    {
      "epoch": 8.457040035987404,
      "grad_norm": 0.3593372702598572,
      "learning_rate": 1.1509024723101602e-05,
      "loss": 1.6012,
      "step": 47000
    },
    {
      "epoch": 8.475033738191632,
      "grad_norm": 0.3729568421840668,
      "learning_rate": 1.1247126206368507e-05,
      "loss": 1.6021,
      "step": 47100
    },
    {
      "epoch": 8.493027440395862,
      "grad_norm": 0.41543519496917725,
      "learning_rate": 1.0988064303487811e-05,
      "loss": 1.5996,
      "step": 47200
    },
    {
      "epoch": 8.51102114260009,
      "grad_norm": 0.3786720335483551,
      "learning_rate": 1.0731847294288033e-05,
      "loss": 1.599,
      "step": 47300
    },
    {
      "epoch": 8.529014844804319,
      "grad_norm": 0.38114064931869507,
      "learning_rate": 1.047848336767271e-05,
      "loss": 1.6049,
      "step": 47400
    },
    {
      "epoch": 8.547008547008547,
      "grad_norm": 0.3909345865249634,
      "learning_rate": 1.02279806213585e-05,
      "loss": 1.5989,
      "step": 47500
    },
    {
      "epoch": 8.565002249212775,
      "grad_norm": 0.3768797814846039,
      "learning_rate": 9.980347061616358e-06,
      "loss": 1.5999,
      "step": 47600
    },
    {
      "epoch": 8.582995951417004,
      "grad_norm": 0.3572114408016205,
      "learning_rate": 9.7355906030158e-06,
      "loss": 1.597,
      "step": 47700
    },
    {
      "epoch": 8.600989653621232,
      "grad_norm": 0.4029565453529358,
      "learning_rate": 9.493719068171814e-06,
      "loss": 1.6053,
      "step": 47800
    },
    {
      "epoch": 8.618983355825462,
      "grad_norm": 0.3903348743915558,
      "learning_rate": 9.254740187494892e-06,
      "loss": 1.5991,
      "step": 47900
    },
    {
      "epoch": 8.63697705802969,
      "grad_norm": 0.39095622301101685,
      "learning_rate": 9.018661598943911e-06,
      "loss": 1.6019,
      "step": 48000
    },
    {
      "epoch": 8.654970760233919,
      "grad_norm": 0.3629990220069885,
      "learning_rate": 8.78549084778212e-06,
      "loss": 1.6021,
      "step": 48100
    },
    {
      "epoch": 8.672964462438147,
      "grad_norm": 0.379496306180954,
      "learning_rate": 8.555235386335903e-06,
      "loss": 1.6,
      "step": 48200
    },
    {
      "epoch": 8.690958164642375,
      "grad_norm": 0.3621987998485565,
      "learning_rate": 8.327902573756595e-06,
      "loss": 1.5993,
      "step": 48300
    },
    {
      "epoch": 8.708951866846604,
      "grad_norm": 0.3695085942745209,
      "learning_rate": 8.103499675785354e-06,
      "loss": 1.6009,
      "step": 48400
    },
    {
      "epoch": 8.726945569050832,
      "grad_norm": 0.37163621187210083,
      "learning_rate": 7.882033864520844e-06,
      "loss": 1.5987,
      "step": 48500
    },
    {
      "epoch": 8.744939271255062,
      "grad_norm": 0.3759768009185791,
      "learning_rate": 7.663512218190061e-06,
      "loss": 1.6016,
      "step": 48600
    },
    {
      "epoch": 8.76293297345929,
      "grad_norm": 0.38059329986572266,
      "learning_rate": 7.447941720922102e-06,
      "loss": 1.6001,
      "step": 48700
    },
    {
      "epoch": 8.780926675663517,
      "grad_norm": 0.3854273855686188,
      "learning_rate": 7.235329262525003e-06,
      "loss": 1.5991,
      "step": 48800
    },
    {
      "epoch": 8.798920377867747,
      "grad_norm": 0.37555965781211853,
      "learning_rate": 7.025681638265369e-06,
      "loss": 1.6036,
      "step": 48900
    },
    {
      "epoch": 8.816914080071975,
      "grad_norm": 0.38286346197128296,
      "learning_rate": 6.819005548651381e-06,
      "loss": 1.5993,
      "step": 49000
    },
    {
      "epoch": 8.834907782276204,
      "grad_norm": 0.38260939717292786,
      "learning_rate": 6.615307599218568e-06,
      "loss": 1.6003,
      "step": 49100
    },
    {
      "epoch": 8.852901484480432,
      "grad_norm": 0.369080513715744,
      "learning_rate": 6.414594300318621e-06,
      "loss": 1.6028,
      "step": 49200
    },
    {
      "epoch": 8.87089518668466,
      "grad_norm": 0.37927719950675964,
      "learning_rate": 6.216872066911417e-06,
      "loss": 1.6014,
      "step": 49300
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 0.3741590678691864,
      "learning_rate": 6.022147218359975e-06,
      "loss": 1.6015,
      "step": 49400
    },
    {
      "epoch": 8.906882591093117,
      "grad_norm": 0.38155654072761536,
      "learning_rate": 5.830425978228404e-06,
      "loss": 1.5978,
      "step": 49500
    },
    {
      "epoch": 8.924876293297347,
      "grad_norm": 0.37694501876831055,
      "learning_rate": 5.6417144740830926e-06,
      "loss": 1.5997,
      "step": 49600
    },
    {
      "epoch": 8.942869995501574,
      "grad_norm": 0.3883765637874603,
      "learning_rate": 5.4560187372968305e-06,
      "loss": 1.5937,
      "step": 49700
    },
    {
      "epoch": 8.960863697705802,
      "grad_norm": 0.3877999484539032,
      "learning_rate": 5.2733447028560315e-06,
      "loss": 1.6005,
      "step": 49800
    },
    {
      "epoch": 8.978857399910032,
      "grad_norm": 0.39006996154785156,
      "learning_rate": 5.093698209171005e-06,
      "loss": 1.6002,
      "step": 49900
    },
    {
      "epoch": 8.99685110211426,
      "grad_norm": 0.37498101592063904,
      "learning_rate": 4.917084997889454e-06,
      "loss": 1.6005,
      "step": 50000
    },
    {
      "epoch": 9.01484480431849,
      "grad_norm": 0.37162354588508606,
      "learning_rate": 4.743510713712896e-06,
      "loss": 1.5935,
      "step": 50100
    },
    {
      "epoch": 9.032838506522717,
      "grad_norm": 0.37639114260673523,
      "learning_rate": 4.572980904216284e-06,
      "loss": 1.5938,
      "step": 50200
    },
    {
      "epoch": 9.050832208726945,
      "grad_norm": 0.36993756890296936,
      "learning_rate": 4.405501019670688e-06,
      "loss": 1.5983,
      "step": 50300
    },
    {
      "epoch": 9.068825910931174,
      "grad_norm": 0.36217308044433594,
      "learning_rate": 4.241076412869094e-06,
      "loss": 1.5977,
      "step": 50400
    },
    {
      "epoch": 9.086819613135402,
      "grad_norm": 0.37971630692481995,
      "learning_rate": 4.079712338955311e-06,
      "loss": 1.595,
      "step": 50500
    },
    {
      "epoch": 9.104813315339632,
      "grad_norm": 0.38030633330345154,
      "learning_rate": 3.92141395525607e-06,
      "loss": 1.5965,
      "step": 50600
    },
    {
      "epoch": 9.12280701754386,
      "grad_norm": 0.36036962270736694,
      "learning_rate": 3.7661863211161607e-06,
      "loss": 1.5958,
      "step": 50700
    },
    {
      "epoch": 9.140800719748087,
      "grad_norm": 0.3718968331813812,
      "learning_rate": 3.6140343977366766e-06,
      "loss": 1.5951,
      "step": 50800
    },
    {
      "epoch": 9.158794421952317,
      "grad_norm": 0.3790462017059326,
      "learning_rate": 3.464963048016556e-06,
      "loss": 1.5924,
      "step": 50900
    },
    {
      "epoch": 9.176788124156545,
      "grad_norm": 0.38264256715774536,
      "learning_rate": 3.318977036397075e-06,
      "loss": 1.5934,
      "step": 51000
    },
    {
      "epoch": 9.194781826360774,
      "grad_norm": 0.36644938588142395,
      "learning_rate": 3.1760810287095876e-06,
      "loss": 1.5924,
      "step": 51100
    },
    {
      "epoch": 9.212775528565002,
      "grad_norm": 0.37031009793281555,
      "learning_rate": 3.0362795920264475e-06,
      "loss": 1.5969,
      "step": 51200
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 0.37592777609825134,
      "learning_rate": 2.8995771945149908e-06,
      "loss": 1.5948,
      "step": 51300
    },
    {
      "epoch": 9.24876293297346,
      "grad_norm": 0.3724820017814636,
      "learning_rate": 2.7659782052947504e-06,
      "loss": 1.5941,
      "step": 51400
    },
    {
      "epoch": 9.266756635177687,
      "grad_norm": 0.37697240710258484,
      "learning_rate": 2.635486894297801e-06,
      "loss": 1.5941,
      "step": 51500
    },
    {
      "epoch": 9.284750337381917,
      "grad_norm": 0.3650287091732025,
      "learning_rate": 2.5081074321323227e-06,
      "loss": 1.5924,
      "step": 51600
    },
    {
      "epoch": 9.302744039586145,
      "grad_norm": 0.37513673305511475,
      "learning_rate": 2.3838438899492667e-06,
      "loss": 1.598,
      "step": 51700
    },
    {
      "epoch": 9.320737741790373,
      "grad_norm": 0.3880167603492737,
      "learning_rate": 2.262700239312254e-06,
      "loss": 1.5934,
      "step": 51800
    },
    {
      "epoch": 9.338731443994602,
      "grad_norm": 0.36956658959388733,
      "learning_rate": 2.144680352070649e-06,
      "loss": 1.6008,
      "step": 51900
    },
    {
      "epoch": 9.35672514619883,
      "grad_norm": 0.3933325409889221,
      "learning_rate": 2.0297880002358107e-06,
      "loss": 1.5964,
      "step": 52000
    },
    {
      "epoch": 9.37471884840306,
      "grad_norm": 0.37212473154067993,
      "learning_rate": 1.9180268558604887e-06,
      "loss": 1.5972,
      "step": 52100
    },
    {
      "epoch": 9.392712550607287,
      "grad_norm": 0.3668314516544342,
      "learning_rate": 1.8094004909215423e-06,
      "loss": 1.597,
      "step": 52200
    },
    {
      "epoch": 9.410706252811515,
      "grad_norm": 0.3684205412864685,
      "learning_rate": 1.7039123772057407e-06,
      "loss": 1.598,
      "step": 52300
    },
    {
      "epoch": 9.428699955015745,
      "grad_norm": 0.35965803265571594,
      "learning_rate": 1.6015658861987526e-06,
      "loss": 1.5952,
      "step": 52400
    },
    {
      "epoch": 9.446693657219972,
      "grad_norm": 0.3543790578842163,
      "learning_rate": 1.5023642889774759e-06,
      "loss": 1.5934,
      "step": 52500
    },
    {
      "epoch": 9.464687359424202,
      "grad_norm": 0.36503827571868896,
      "learning_rate": 1.4063107561054556e-06,
      "loss": 1.5943,
      "step": 52600
    },
    {
      "epoch": 9.48268106162843,
      "grad_norm": 0.36525553464889526,
      "learning_rate": 1.3134083575315203e-06,
      "loss": 1.5935,
      "step": 52700
    },
    {
      "epoch": 9.50067476383266,
      "grad_norm": 0.37335869669914246,
      "learning_rate": 1.223660062491694e-06,
      "loss": 1.5961,
      "step": 52800
    },
    {
      "epoch": 9.518668466036887,
      "grad_norm": 0.36883631348609924,
      "learning_rate": 1.1370687394143042e-06,
      "loss": 1.5974,
      "step": 52900
    },
    {
      "epoch": 9.536662168241115,
      "grad_norm": 0.36886101961135864,
      "learning_rate": 1.053637155828302e-06,
      "loss": 1.5934,
      "step": 53000
    },
    {
      "epoch": 9.554655870445345,
      "grad_norm": 0.38070645928382874,
      "learning_rate": 9.73367978274764e-07,
      "loss": 1.5947,
      "step": 53100
    },
    {
      "epoch": 9.572649572649572,
      "grad_norm": 0.3603913486003876,
      "learning_rate": 8.962637722217503e-07,
      "loss": 1.5973,
      "step": 53200
    },
    {
      "epoch": 9.590643274853802,
      "grad_norm": 0.36291587352752686,
      "learning_rate": 8.22327001982226e-07,
      "loss": 1.5941,
      "step": 53300
    },
    {
      "epoch": 9.60863697705803,
      "grad_norm": 0.35595011711120605,
      "learning_rate": 7.515600306353565e-07,
      "loss": 1.5972,
      "step": 53400
    },
    {
      "epoch": 9.626630679262258,
      "grad_norm": 0.3693908154964447,
      "learning_rate": 6.839651199509689e-07,
      "loss": 1.595,
      "step": 53500
    },
    {
      "epoch": 9.644624381466487,
      "grad_norm": 0.3679395914077759,
      "learning_rate": 6.195444303172315e-07,
      "loss": 1.5984,
      "step": 53600
    },
    {
      "epoch": 9.662618083670715,
      "grad_norm": 0.3690735697746277,
      "learning_rate": 5.583000206716648e-07,
      "loss": 1.5965,
      "step": 53700
    },
    {
      "epoch": 9.680611785874945,
      "grad_norm": 0.3621635138988495,
      "learning_rate": 5.002338484352942e-07,
      "loss": 1.5925,
      "step": 53800
    },
    {
      "epoch": 9.698605488079172,
      "grad_norm": 0.36900269985198975,
      "learning_rate": 4.4534776945007737e-07,
      "loss": 1.5971,
      "step": 53900
    },
    {
      "epoch": 9.7165991902834,
      "grad_norm": 0.3658078610897064,
      "learning_rate": 3.9364353791964124e-07,
      "loss": 1.5977,
      "step": 54000
    },
    {
      "epoch": 9.73459289248763,
      "grad_norm": 0.3614434003829956,
      "learning_rate": 3.4512280635315977e-07,
      "loss": 1.5933,
      "step": 54100
    },
    {
      "epoch": 9.752586594691858,
      "grad_norm": 0.3530800938606262,
      "learning_rate": 2.9978712551259614e-07,
      "loss": 1.5961,
      "step": 54200
    },
    {
      "epoch": 9.770580296896087,
      "grad_norm": 0.36066195368766785,
      "learning_rate": 2.576379443630761e-07,
      "loss": 1.5933,
      "step": 54300
    },
    {
      "epoch": 9.788573999100315,
      "grad_norm": 0.3572810888290405,
      "learning_rate": 2.1867661002663575e-07,
      "loss": 1.5965,
      "step": 54400
    },
    {
      "epoch": 9.806567701304543,
      "grad_norm": 0.36484235525131226,
      "learning_rate": 1.829043677391229e-07,
      "loss": 1.5931,
      "step": 54500
    },
    {
      "epoch": 9.824561403508772,
      "grad_norm": 0.3700299859046936,
      "learning_rate": 1.5032236081042873e-07,
      "loss": 1.596,
      "step": 54600
    },
    {
      "epoch": 9.842555105713,
      "grad_norm": 0.3780733048915863,
      "learning_rate": 1.2093163058791712e-07,
      "loss": 1.5974,
      "step": 54700
    },
    {
      "epoch": 9.86054880791723,
      "grad_norm": 0.356414258480072,
      "learning_rate": 9.473311642319572e-08,
      "loss": 1.5935,
      "step": 54800
    },
    {
      "epoch": 9.878542510121457,
      "grad_norm": 0.35913392901420593,
      "learning_rate": 7.172765564200657e-08,
      "loss": 1.5922,
      "step": 54900
    },
    {
      "epoch": 9.896536212325685,
      "grad_norm": 0.36885884404182434,
      "learning_rate": 5.1915983517547564e-08,
      "loss": 1.5937,
      "step": 55000
    },
    {
      "epoch": 9.914529914529915,
      "grad_norm": 0.37123531103134155,
      "learning_rate": 3.5298733246946766e-08,
      "loss": 1.5968,
      "step": 55100
    },
    {
      "epoch": 9.932523616734143,
      "grad_norm": 0.3609851002693176,
      "learning_rate": 2.1876435930989758e-08,
      "loss": 1.5963,
      "step": 55200
    },
    {
      "epoch": 9.950517318938372,
      "grad_norm": 0.3595050573348999,
      "learning_rate": 1.164952055718871e-08,
      "loss": 1.5974,
      "step": 55300
    },
    {
      "epoch": 9.9685110211426,
      "grad_norm": 0.36182740330696106,
      "learning_rate": 4.6183139860600524e-09,
      "loss": 1.5978,
      "step": 55400
    },
    {
      "epoch": 9.986504723346828,
      "grad_norm": 0.356282114982605,
      "learning_rate": 7.830409406772709e-10,
      "loss": 1.5977,
      "step": 55500
    },
    {
      "epoch": 9.99910031488979,
      "step": 55570,
      "total_flos": 2.4269556997834146e+19,
      "train_loss": 1.6956138645163195,
      "train_runtime": 123505.5395,
      "train_samples_per_second": 921.547,
      "train_steps_per_second": 0.45
    }
  ],
  "logging_steps": 100,
  "max_steps": 55570,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4269556997834146e+19,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
