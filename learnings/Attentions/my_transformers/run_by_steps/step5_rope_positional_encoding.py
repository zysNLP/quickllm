# -*- coding: utf-8 -*-
"""
Step 5: RoPEä½ç½®ç¼–ç å¯è§†åŒ–
ç”Ÿæˆå’Œå¯è§†åŒ–RoPEä½ç½®ç¼–ç çŸ©é˜µ
"""

import os
import torch
import matplotlib.pyplot as plt
import numpy as np
import math


def get_device():
    """è‡ªåŠ¨æ£€æµ‹å¯ç”¨è®¾å¤‡"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name()}")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")  # Apple Silicon GPU
        print("âœ… ä½¿ç”¨ Apple Silicon GPU (MPS)")
    else:
        device = torch.device("cpu")
        print("âœ… ä½¿ç”¨ CPU")
    return device


class RoPEVisualizer:
    def __init__(self, max_len, d_model, nums_head=8, batch_size=1, device=None):
        self.max_len = max_len
        self.d_model = d_model
        self.nums_head = nums_head
        self.batch_size = batch_size

        if device is None:
            self.device = get_device()
        else:
            self.device = device

    def sinusoidal_position_embedding(self):
        """
        ç”ŸæˆRoPEä½ç½®ç¼–ç çŸ©é˜µ
        è¿”å›ž: [batch_size, nums_head, max_len, d_model]
        """
        # (max_len, 1)
        position = torch.arange(0, self.max_len, dtype=torch.float).unsqueeze(-1)

        # (d_model//2)
        ids = torch.arange(0, self.d_model // 2, dtype=torch.float)
        theta = torch.pow(10000, -2 * ids / self.d_model)

        # (max_len, d_model//2)
        embeddings = position * theta

        # (max_len, d_model//2, 2)
        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)

        # (batch_size, nums_head, max_len, d_model//2, 2)
        embeddings = embeddings.repeat((self.batch_size, self.nums_head, *([1] * len(embeddings.shape))))

        # (batch_size, nums_head, max_len, d_model)
        embeddings = torch.reshape(embeddings, (self.batch_size, self.nums_head, self.max_len, self.d_model))

        return embeddings.to(self.device)

    def get_rope_embedding_matrix(self):
        """
        èŽ·å–RoPEä½ç½®ç¼–ç çŸ©é˜µç”¨äºŽå¯è§†åŒ–
        è¿”å›ž: [max_len, d_model]
        """
        # åªå–ç¬¬ä¸€ä¸ªbatchå’Œç¬¬ä¸€ä¸ªheadçš„ä½ç½®ç¼–ç 
        rope_emb = self.sinusoidal_position_embedding()
        return rope_emb[0, 0].detach().cpu()  # [max_len, d_model]

    def get_rotation_matrices(self, positions_to_show=5):
        """
        èŽ·å–æ—‹è½¬çŸ©é˜µçš„å¯è§†åŒ–æ•°æ®
        å¯¹äºŽæ¯ä¸ªä½ç½®ï¼Œè®¡ç®—æ—‹è½¬çŸ©é˜µå¯¹å‘é‡çš„å½±å“
        """
        # ç”Ÿæˆä¸€äº›æµ‹è¯•å‘é‡
        test_vectors = []
        for i in range(4):
            angle = i * math.pi / 4  # 0, 45, 90, 135åº¦
            vec = torch.tensor([math.cos(angle), math.sin(angle)], dtype=torch.float32)
            test_vectors.append(vec)

        # è®¡ç®—æ—‹è½¬æ•ˆæžœ
        rotation_data = []
        for pos in range(min(positions_to_show, self.max_len)):
            pos_emb = self.sinusoidal_position_embedding()[0, 0, pos]  # å–ç¬¬ä¸€ä¸ªä½ç½®ç¼–ç 

            rotated_vectors = []
            for vec in test_vectors:
                # ç®€åŒ–ç‰ˆçš„æ—‹è½¬è®¡ç®—ï¼ˆåªè€ƒè™‘å‰ä¸¤ä¸ªç»´åº¦ï¼‰
                cos_theta = pos_emb[1]  # cosåˆ†é‡
                sin_theta = pos_emb[0]  # sinåˆ†é‡

                # æ—‹è½¬çŸ©é˜µ [cos, -sin; sin, cos]
                rotation_matrix = torch.tensor([
                    [cos_theta, -sin_theta],
                    [sin_theta, cos_theta]
                ])

                rotated_vec = torch.matmul(rotation_matrix, vec)
                rotated_vectors.append({
                    'original': vec.numpy(),
                    'rotated': rotated_vec.numpy(),
                    'position': pos
                })

            rotation_data.append(rotated_vectors)

        return rotation_data


def plot_rope_embedding(rope_embedding: torch.Tensor):
    """
    å¯è§†åŒ–RoPEä½ç½®ç¼–ç çŸ©é˜µ
    å‚æ•°:
        rope_embedding: [L, D] çš„å¼ é‡
    """
    pe = rope_embedding.numpy()  # [L, D]

    plt.figure(figsize=(15, 10))

    # ä¸»å›¾ï¼šRoPEä½ç½®ç¼–ç çš„çƒ­åŠ›å›¾
    plt.subplot(2, 2, 1)
    plt.pcolormesh(pe, cmap='RdBu')
    plt.xlabel("Depth (d_model)")
    plt.xlim((0, pe.shape[1]))
    plt.ylabel("Position (pos)")
    plt.colorbar(label='Encoding Value')
    plt.title("RoPE Positional Encoding Heatmap")

    # å­å›¾ï¼šæ­£å¼¦å’Œä½™å¼¦åˆ†é‡
    plt.subplot(2, 2, 2)
    positions_to_plot = min(8, pe.shape[0])
    for pos in range(positions_to_plot):
        plt.plot(pe[pos, :], label=f'Pos {pos}', alpha=0.7, linewidth=1)
    plt.xlabel("Dimension")
    plt.ylabel("Encoding Value")
    plt.title("RoPE Encoding by Position")
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

    # å­å›¾ï¼šæ­£å¼¦åˆ†é‡ï¼ˆå¶æ•°ç»´åº¦ï¼‰
    plt.subplot(2, 2, 3)
    sin_components = pe[:, 0::2]  # æ‰€æœ‰ä½ç½®çš„sinåˆ†é‡
    for pos in range(positions_to_plot):
        plt.plot(sin_components[pos, :25], label=f'Pos {pos}', alpha=0.7, linewidth=2)
    plt.xlabel("Sin Component Index")
    plt.ylabel("Sin Value")
    plt.title("RoPE Sin Components (First 25)")
    plt.legend()

    # å­å›¾ï¼šä½™å¼¦åˆ†é‡ï¼ˆå¥‡æ•°ç»´åº¦ï¼‰
    plt.subplot(2, 2, 4)
    cos_components = pe[:, 1::2]  # æ‰€æœ‰ä½ç½®çš„cosåˆ†é‡
    for pos in range(positions_to_plot):
        plt.plot(cos_components[pos, :25], label=f'Pos {pos}', alpha=0.7, linewidth=2)
    plt.xlabel("Cos Component Index")
    plt.ylabel("Cos Value")
    plt.title("RoPE Cos Components (First 25)")
    plt.legend()

    plt.tight_layout()
    plt.savefig('images/step5_rope_positional_encoding1.png', dpi=300, bbox_inches='tight')


def plot_rotation_effect(rotation_data):
    """
    å¯è§†åŒ–æ—‹è½¬æ•ˆæžœ
    """
    plt.figure(figsize=(12, 8))

    positions = len(rotation_data)
    vectors_per_pos = len(rotation_data[0]) if rotation_data else 0

    for pos_idx, pos_vectors in enumerate(rotation_data):
        plt.subplot(2, 3, pos_idx + 1)

        # ç»˜åˆ¶å•ä½åœ†
        circle = plt.Circle((0, 0), 1, fill=False, color='gray', linestyle='--', alpha=0.3)
        plt.gca().add_patch(circle)

        colors = ['red', 'blue', 'green', 'orange']

        for vec_idx, vec_data in enumerate(pos_vectors):
            orig = vec_data['original']
            rotated = vec_data['rotated']
            color = colors[vec_idx % len(colors)]

            # ç»˜åˆ¶åŽŸå§‹å‘é‡
            plt.arrow(0, 0, orig[0], orig[1],
                      head_width=0.05, head_length=0.1,
                      fc=color, ec=color, alpha=0.6,
                      label=f'Vec{vec_idx}' if pos_idx == 0 else "")

            # ç»˜åˆ¶æ—‹è½¬åŽçš„å‘é‡
            plt.arrow(0, 0, rotated[0], rotated[1],
                      head_width=0.05, head_length=0.1,
                      fc=color, ec=color, alpha=1.0, linestyle='-')

        plt.xlim(-1.2, 1.2)
        plt.ylim(-1.2, 1.2)
        plt.grid(True, alpha=0.3)
        plt.gca().set_aspect('equal')
        plt.title(f'Position {pos_idx}')
        plt.xlabel('X')
        plt.ylabel('Y')

    plt.suptitle('RoPE Rotation Effect on Different Positions')
    plt.tight_layout()
    plt.savefig('images/step5_rope_positional_encoding2.png', dpi=300, bbox_inches='tight')


def analyze_rope_encoding(rope_embedding: torch.Tensor):
    """
    åˆ†æžRoPEä½ç½®ç¼–ç çš„ç‰¹æ€§
    """
    pe = rope_embedding.numpy()  # [L, D]

    print(f"ðŸ“Š RoPEä½ç½®ç¼–ç åˆ†æž:")
    print(f"   åºåˆ—é•¿åº¦: {pe.shape[0]}")
    print(f"   åµŒå…¥ç»´åº¦: {pe.shape[1]}")
    print(f"   æ•°å€¼èŒƒå›´: [{pe.min():.4f}, {pe.max():.4f}]")
    print(f"   å‡å€¼: {pe.mean():.4f}")
    print(f"   æ ‡å‡†å·®: {pe.std():.4f}")

    # åˆ†æžæ­£å¼¦å’Œä½™å¼¦åˆ†é‡
    sin_components = pe[:, 0::2]
    cos_components = pe[:, 1::2]

    print(f"\nðŸ” åˆ†é‡åˆ†æž:")
    print(f"   æ­£å¼¦åˆ†é‡èŒƒå›´: [{sin_components.min():.4f}, {sin_components.max():.4f}]")
    print(f"   ä½™å¼¦åˆ†é‡èŒƒå›´: [{cos_components.min():.4f}, {cos_components.max():.4f}]")
    print(f"   æ­£å¼¦åˆ†é‡å‡å€¼: {sin_components.mean():.4f}")
    print(f"   ä½™å¼¦åˆ†é‡å‡å€¼: {cos_components.mean():.4f}")

    # åˆ†æžä½ç½®é—´çš„ç›¸ä¼¼æ€§
    print(f"\nðŸ“ˆ ä½ç½®ç›¸ä¼¼æ€§åˆ†æž:")
    positions_to_check = min(5, pe.shape[0])
    for i in range(positions_to_check):
        for j in range(i + 1, positions_to_check):
            similarity = np.corrcoef(pe[i], pe[j])[0, 1]
            print(f"   ä½ç½® {i} ä¸Žä½ç½® {j} çš„ç›¸ä¼¼åº¦: {similarity:.4f}")


def verify_rope_encoding(rope_embedding: torch.Tensor):
    """
    éªŒè¯RoPEä½ç½®ç¼–ç çš„æ­£ç¡®æ€§
    """
    pe = rope_embedding.numpy()  # [L, D]

    print(f"\nâœ… RoPEä½ç½®ç¼–ç éªŒè¯:")

    # æ£€æŸ¥æ•°å€¼èŒƒå›´
    assert pe.min() >= -1.0 and pe.max() <= 1.0, "RoPEç¼–ç å€¼è¶…å‡ºé¢„æœŸèŒƒå›´"
    print("   âœ“ æ•°å€¼èŒƒå›´éªŒè¯é€šè¿‡")

    # æ£€æŸ¥æ­£å¼¦åˆ†é‡
    sin_components = pe[:, 0::2]
    assert abs(sin_components[0, 0]) < 1e-6, f"ä½ç½®0çš„æ­£å¼¦å€¼åº”è¯¥æŽ¥è¿‘0ï¼Œå®žé™…ä¸º{sin_components[0, 0]}"
    print("   âœ“ æ­£å¼¦åˆ†é‡éªŒè¯é€šè¿‡")

    # æ£€æŸ¥ä½™å¼¦åˆ†é‡
    cos_components = pe[:, 1::2]
    assert abs(cos_components[0, 0] - 1.0) < 1e-6, f"ä½ç½®0çš„ä½™å¼¦å€¼åº”è¯¥æŽ¥è¿‘1ï¼Œå®žé™…ä¸º{cos_components[0, 0]}"
    print("   âœ“ ä½™å¼¦åˆ†é‡éªŒè¯é€šè¿‡")

    # æ£€æŸ¥ä¸åŒä½ç½®ç¼–ç æ˜¯å¦ä¸åŒ
    unique_positions = len(set(tuple(row) for row in pe))
    assert unique_positions == pe.shape[0], "å­˜åœ¨é‡å¤çš„ä½ç½®ç¼–ç "
    print("   âœ“ ä½ç½®å”¯ä¸€æ€§éªŒè¯é€šè¿‡")

    print("   ðŸŽ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼RoPEä½ç½®ç¼–ç ç”Ÿæˆæ­£ç¡®ã€‚")


if __name__ == "__main__":
    print("=" * 60)
    print("Step 5: RoPEä½ç½®ç¼–ç å¯è§†åŒ–")
    print("=" * 60)

    # å‚æ•°è®¾ç½®
    max_length = 50  # æœ€å¤§åºåˆ—é•¿åº¦
    d_model = 128  # åµŒå…¥ç»´åº¦
    nums_head = 8  # æ³¨æ„åŠ›å¤´æ•°

    print(f"ðŸ”§ RoPEä½ç½®ç¼–ç å‚æ•°:")
    print(f"   æœ€å¤§åºåˆ—é•¿åº¦: {max_length}")
    print(f"   åµŒå…¥ç»´åº¦: {d_model}")
    print(f"   æ³¨æ„åŠ›å¤´æ•°: {nums_head}")

    try:
        # èŽ·å–è®¾å¤‡
        device = get_device()

        # 1. åˆå§‹åŒ–RoPEå¯è§†åŒ–å™¨
        print(f"\nðŸ”¨ åˆå§‹åŒ–RoPEå¯è§†åŒ–å™¨...")
        rope_viz = RoPEVisualizer(
            max_len=max_length,
            d_model=d_model,
            nums_head=nums_head,
            batch_size=1,
            device=device
        )

        # 2. ç”ŸæˆRoPEä½ç½®ç¼–ç 
        print(f"ðŸ”¨ ç”ŸæˆRoPEä½ç½®ç¼–ç ...")
        rope_embedding = rope_viz.get_rope_embedding_matrix()

        print(f"âœ… RoPEä½ç½®ç¼–ç ç”Ÿæˆå®Œæˆï¼")
        print(f"ðŸ“Š ä½ç½®ç¼–ç å½¢çŠ¶: {rope_embedding.shape}")

        # 3. éªŒè¯RoPEä½ç½®ç¼–ç 
        verify_rope_encoding(rope_embedding)

        # 4. åˆ†æžRoPEä½ç½®ç¼–ç 
        print(f"\nðŸ” åˆ†æžRoPEä½ç½®ç¼–ç ç‰¹æ€§...")
        analyze_rope_encoding(rope_embedding)

        # 5. å¯è§†åŒ–RoPEä½ç½®ç¼–ç çŸ©é˜µ
        print(f"\nðŸ“Š å¯è§†åŒ–RoPEä½ç½®ç¼–ç çŸ©é˜µ...")
        plot_rope_embedding(rope_embedding)

        # 6. å¯è§†åŒ–æ—‹è½¬æ•ˆæžœ
        print(f"\nðŸ”„ å¯è§†åŒ–æ—‹è½¬æ•ˆæžœ...")
        rotation_data = rope_viz.get_rotation_matrices(positions_to_show=6)
        plot_rotation_effect(rotation_data)

        print(f"\nâœ… RoPEä½ç½®ç¼–ç å¯è§†åŒ–å®Œæˆï¼")

        # 7. å±•ç¤ºRoPEä½ç½®ç¼–ç çš„æ•°å€¼
        print(f"\nðŸ“ RoPEä½ç½®ç¼–ç æ•°å€¼ç¤ºä¾‹ (å‰5ä¸ªä½ç½®ï¼Œå‰10ä¸ªç»´åº¦):")
        pe_np = rope_embedding.numpy()
        for i in range(min(5, pe_np.shape[0])):
            values_str = " ".join([f"{x:6.3f}" for x in pe_np[i, :10]])
            print(f"   ä½ç½® {i:2d}: [{values_str}]")

    except Exception as e:
        print(f"âŒ RoPEä½ç½®ç¼–ç ç”Ÿæˆå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        print("ðŸ’¡ å»ºè®®æ£€æŸ¥:")
        print("   1. PyTorch æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("   2. è®¾å¤‡æ˜¯å¦å¯ç”¨")
        print("   3. å‚æ•°è®¾ç½®æ˜¯å¦åˆç†")