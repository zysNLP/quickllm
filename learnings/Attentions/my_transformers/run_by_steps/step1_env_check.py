# -*- coding: utf-8 -*-
"""
Step 1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–åº“ç‰ˆæœ¬
æ£€æŸ¥ PyTorch ç¯å¢ƒä¿¡æ¯ã€GPU çŠ¶æ€ï¼Œä»¥åŠå¸¸ç”¨ä¾èµ–åº“ç‰ˆæœ¬
"""

import os
import sys
import torch
import numpy as np
import pandas as pd
import matplotlib as mpl
from loguru import logger

# è®¾ç½®GPUè®¾å¤‡
os.environ["CUDA_VISIBLE_DEVICES"] = "2"

def check_env():
    """
    æ£€æŸ¥ PyTorch ç¯å¢ƒä¿¡æ¯ã€GPU çŠ¶æ€ï¼Œä»¥åŠå¸¸ç”¨ä¾èµ–åº“ç‰ˆæœ¬ã€‚
    è¿”å›æ¨èçš„ device ('cuda' æˆ– 'cpu')ã€‚
    """
    logger.info("===== PyTorch & ç³»ç»Ÿä¿¡æ¯ =====")
    logger.info(f"torch.__version__: {torch.__version__}")
    logger.info(f"python version: {sys.version_info}")

    logger.info("\n===== å¸¸ç”¨åº“ç‰ˆæœ¬ =====")
    for module in (mpl, np, pd, torch):
        logger.info(f"{module.__name__}: {module.__version__}")

    logger.info("\n===== GPU æ£€æŸ¥ =====")
    logger.info(f"torch.cuda.is_available(): {torch.cuda.is_available()}")
    logger.info(f"torch.version.cuda: {torch.version.cuda}")
    try:
        logger.info(f"cudnn version: {torch.backends.cudnn.version()}")
    except Exception as e:
        logger.info(f"cudnn version: N/A, {e}")

    if torch.cuda.is_available():
        logger.info(f"GPU count: {torch.cuda.device_count()}")
        logger.info(f"Current device id: {torch.cuda.current_device()}")
        logger.info(f"GPU name: {torch.cuda.get_device_name(0)}")
        logger.info(f"bfloat16 supported: {torch.cuda.is_bf16_supported()}")

        # å¯ç”¨ TF32
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        try:
            torch.set_float32_matmul_precision("high")
        except Exception:
            pass
        device = "cuda"
    else:
        logger.info("âš ï¸ æ²¡æ£€æµ‹åˆ° CUDAï¼Œå¯å¼ºåˆ¶ device='cpu' è¿è¡Œï¼Œä½†é€Ÿåº¦ä¼šæ…¢")
        device = "cpu"

    logger.info(f"\næ¨èä½¿ç”¨ device: {device}")
    return device

if __name__ == "__main__":
    print("=" * 60)
    print("Step 1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–åº“ç‰ˆæœ¬")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    device = check_env()
    
    print(f"\nâœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼")
    print(f"ğŸ“± æ¨èä½¿ç”¨è®¾å¤‡: {device}")
    print(f"ğŸ”§ PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    if torch.cuda.is_available():
        print(f"ğŸš€ GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
