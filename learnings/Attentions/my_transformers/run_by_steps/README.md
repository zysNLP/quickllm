# Transformer è®­ç»ƒåˆ†æ­¥è„šæœ¬

è¿™ä¸ªæ–‡ä»¶å¤¹åŒ…å«äº†å°†åŸå§‹ `train.py` æŒ‰ç…§ç¨‹åºè¿è¡Œå…ˆåé¡ºåºåˆ†è§£çš„9ä¸ªç‹¬ç«‹Pythonè„šæœ¬ï¼Œæ¨¡æ‹Ÿç”¨Jupyterè¿è¡Œä»£ç æŸ¥çœ‹ç»“æœçš„è¿‡ç¨‹ã€‚

## è„šæœ¬è¯´æ˜

### Step 1: ç¯å¢ƒæ£€æŸ¥ (`step1_env_check.py`)
- æ£€æŸ¥ PyTorch ç¯å¢ƒä¿¡æ¯ã€GPU çŠ¶æ€
- æ˜¾ç¤ºå¸¸ç”¨ä¾èµ–åº“ç‰ˆæœ¬
- è®¾ç½®GPUè®¾å¤‡å¹¶å¯ç”¨ä¼˜åŒ–é€‰é¡¹

### Step 2: æ•°æ®åŠ è½½ (`step2_data_loading.py`)
- åŠ è½½è‘¡è„ç‰™è¯­-è‹±è¯­ç¿»è¯‘æ•°æ®é›† (TED Talks)
- æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯å’Œæ ·æœ¬é¢„è§ˆ
- éªŒè¯æ•°æ®åŠ è½½æ˜¯å¦æˆåŠŸ

### Step 3: Tokenizerè®­ç»ƒ (`step3_tokenizer.py`)
- è®­ç»ƒè‘¡è„ç‰™è¯­å’Œè‹±è¯­çš„ ByteLevel BPE Tokenizer
- æµ‹è¯•tokenizerçš„ç¼–ç /è§£ç åŠŸèƒ½
- ä¿å­˜tokenizeråˆ°æœ¬åœ°æ–‡ä»¶

### Step 4: DataLoaderæ„å»º (`step4_dataloader.py`)
- æ„å»ºè®­ç»ƒå’ŒéªŒè¯ DataLoader
- å®ç°åŠ¨æ€paddingå’Œåºåˆ—è¿‡æ»¤
- æµ‹è¯•DataLoaderçš„è¾“å‡ºæ ¼å¼

### Step 5: ä½ç½®ç¼–ç å¯è§†åŒ– (`step5_position_encoding.py`)
- ç”Ÿæˆä½ç½®ç¼–ç çŸ©é˜µ
- å¯è§†åŒ–ä½ç½®ç¼–ç æ¨¡å¼
- åˆ†æä½ç½®ç¼–ç çš„ç‰¹æ€§

### Step 6: Transformeræ¨¡å‹æ„å»º (`step6_model_building.py`)
- å®ç°å®Œæ•´çš„Transformeræ¶æ„
- åŒ…æ‹¬Encoderã€Decoderã€MultiHeadAttentionç­‰ç»„ä»¶
- æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­å’Œå‚æ•°ç»Ÿè®¡

### Step 7: ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ (`step7_optimizer_scheduler.py`)
- è®¾ç½®AdamWä¼˜åŒ–å™¨
- é…ç½®Cosineå­¦ä¹ ç‡è°ƒåº¦å™¨with warmup
- å¯è§†åŒ–å­¦ä¹ ç‡å˜åŒ–æ›²çº¿

### Step 8: æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ (`step8_training.py`)
- å®ç°å®Œæ•´çš„è®­ç»ƒå¾ªç¯
- åŒ…æ‹¬æŸå¤±è®¡ç®—ã€åå‘ä¼ æ’­ã€æ¢¯åº¦è£å‰ª
- è®­ç»ƒè¿‡ç¨‹ç›‘æ§å’Œcheckpointä¿å­˜
- ç»˜åˆ¶è®­ç»ƒæ›²çº¿

### Step 9: æ¨¡å‹è¯„ä¼°å’Œç¿»è¯‘æµ‹è¯• (`step9_evaluation.py`)
- å®ç°æ¨¡å‹æ¨ç†å’Œç¿»è¯‘åŠŸèƒ½
- æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–
- ç¿»è¯‘è´¨é‡è¯„ä¼°å’Œæ€§èƒ½åˆ†æ

## ä½¿ç”¨æ–¹æ³•

### é¡ºåºè¿è¡Œï¼ˆæ¨èï¼‰
```bash
# æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰è„šæœ¬
python step1_env_check.py
python step2_data_loading.py
python step3_tokenizer.py
python step4_dataloader.py
python step5_position_encoding.py
python step6_model_building.py
python step7_optimizer_scheduler.py
python step8_training.py
python step9_evaluation.py
```

### å•ç‹¬è¿è¡Œ
æ¯ä¸ªè„šæœ¬éƒ½å¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Œä½†éœ€è¦æ³¨æ„ä¾èµ–å…³ç³»ï¼š
- Step 1: ç‹¬ç«‹è¿è¡Œ
- Step 2: ç‹¬ç«‹è¿è¡Œ
- Step 3: ä¾èµ– Step 2
- Step 4: ä¾èµ– Step 2, 3
- Step 5: ç‹¬ç«‹è¿è¡Œ
- Step 6: ç‹¬ç«‹è¿è¡Œ
- Step 7: ç‹¬ç«‹è¿è¡Œ
- Step 8: ä¾èµ– Step 6, 7
- Step 9: ä¾èµ– Step 6

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®è·¯å¾„**: è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Œé»˜è®¤è·¯å¾„ä¸ºï¼š
   - è®­ç»ƒé›†: `/data2/workspace/yszhang/train_transformers/tensorflow_datasets/ted_pt_en_train.csv`
   - éªŒè¯é›†: `/data2/workspace/yszhang/train_transformers/tensorflow_datasets/ted_pt_en_test.csv`

2. **GPUè®¾ç½®**: ä»¥ä¸‹è„šæœ¬è®¾ç½®äº† `CUDA_VISIBLE_DEVICES="2"`ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼š
   - step1_env_check.py (ç¯å¢ƒæ£€æŸ¥)
   - step5_position_encoding.py (ä½ç½®ç¼–ç )
   - step6_model_building.py (æ¨¡å‹æ„å»º)
   - step7_optimizer_scheduler.py (ä¼˜åŒ–å™¨)
   - step8_training.py (æ¨¡å‹è®­ç»ƒ)
   - step9_evaluation.py (æ¨¡å‹è¯„ä¼°)

3. **ä¾èµ–åº“**: ç¡®ä¿å®‰è£…äº†ä»¥ä¸‹ä¾èµ–ï¼š
   ```
   torch
   transformers
   datasets
   tokenizers
   matplotlib
   loguru
   ```

4. **å†…å­˜è¦æ±‚**: è®­ç»ƒè¿‡ç¨‹éœ€è¦è¾ƒå¤§çš„å†…å­˜ï¼Œå»ºè®®è‡³å°‘8GB RAM

5. **è®­ç»ƒæ—¶é—´**: å®Œæ•´è®­ç»ƒéœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å…ˆç”¨å°‘é‡epochæµ‹è¯•

## è¾“å‡ºè¯´æ˜

æ¯ä¸ªè„šæœ¬éƒ½ä¼šè¾“å‡ºï¼š
- ğŸ”§ å‚æ•°é…ç½®ä¿¡æ¯
- ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡
- âœ… æˆåŠŸå®Œæˆæç¤º
- âŒ é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®

## è‡ªå®šä¹‰ä¿®æ”¹

å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š
- æ¨¡å‹ç»“æ„å‚æ•°ï¼ˆå±‚æ•°ã€ç»´åº¦ã€æ³¨æ„åŠ›å¤´æ•°ç­‰ï¼‰
- è®­ç»ƒè¶…å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€æ‰¹å¤§å°ã€è®­ç»ƒè½®æ•°ç­‰ï¼‰
- æ•°æ®è·¯å¾„å’Œæ–‡ä»¶å
- GPUè®¾å¤‡è®¾ç½®

## æ•…éšœæ’é™¤

1. **æ•°æ®åŠ è½½å¤±è´¥**: æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼
2. **GPUå†…å­˜ä¸è¶³**: å‡å°æ‰¹å¤§å°æˆ–æ¨¡å‹ç»´åº¦
3. **ä¾èµ–åº“ç¼ºå¤±**: å®‰è£…æ‰€éœ€çš„PythonåŒ…
4. **æƒé™é—®é¢˜**: ç¡®ä¿æœ‰è¯»å†™checkpointç›®å½•çš„æƒé™
