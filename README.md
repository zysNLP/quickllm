## ä¸€. ç®€ä»‹

LLMå­¦ä¹ èµ„æºåº“ã€‚ä½¿ç”¨pytorchå’Œéƒ¨åˆ†Tensorflow2å®ç°ï¼Œå¯ä»¥ **<u>*æœ¬åœ°è¿è¡Œå’Œè°ƒè¯•*</u>** çš„å¤§æ¨¡å‹LLMç›¸å…³çš„åº”ç”¨

#### **æ ¸å¿ƒåŠŸèƒ½**ï¼š PPOã€GRPOã€Deepseek-V3ã€MLAã€Mixtral-8x7Bã€MOEã€Qwen-TensorRTç­‰

å†æ¬¡å¼ºè°ƒï¼šå¼ºè°ƒæœ¬åœ°è°ƒè¯•ã€ä»£ç è·³è½¬ã€å¿«é€ŸæŒæ¡LLMï¼basic_llm\*å’Œbasic_run\*åˆ†åˆ«æ˜¯è°ƒè¯•å’Œè¿è¡Œæ¨¡å¼

é…å¥—è¯¾ç¨‹[ã€ŠAIGCå¤§æ¨¡å‹ç†è®ºä¸å·¥ä¸šè½åœ°å®æˆ˜ã€‹](https://edu.csdn.net/course/detail/39082)ï¼Œ[relation](https://github.com/zysNLP/base_course/tree/main)

### æœ€æ–°æ›´æ–°ï¼š
- 20250516ï¼šğŸ¯feat:(learnings/tiny-grpo/*):æ·»åŠ GRPOä½¿ç”¨Qwen2.5-0.5Bå’Œgsm8k_chineseæ•°æ®é›†è®­ç»ƒå’Œéƒ¨ç½²å®Œæ•´æµç¨‹
- 20250516ï¼šğŸ¯feat:(learnings/qwen25-vl_sft)æ·»åŠ Qwen2.5-VL-Instructæ¨¡å‹è®­ç»ƒã€æ¨ç†ã€éƒ¨ç½²æœåŠ¡å’Œè¯·æ±‚æœåŠ¡
- 20250514ï¼šğŸ¯feat:(learnings/unsloth_models)æ·»åŠ ã€ŠåŸºäºunslothè®­ç»ƒä¸éƒ¨ç½²å®è·µDeepSeek-R1 æ³•å¾‹æ¨ç†æ¨¡å‹ã€‹åŒ…æ‹¬è®­ç»ƒã€æ¨ç†ã€éƒ¨ç½²æœåŠ¡å’Œè¯·æ±‚æœåŠ¡ï¼‰
- 20250225ï¼šğŸ¯feat:(learnings/DeepSeek-V3)æ·»åŠ deepseek-V3å®˜æ–¹æ¨ç†ä»£ç ï¼ˆå¯ä½¿ç”¨learnings/DeepSeek-V3-codes/inference/model.pyè„šæœ¬åœ¨æœ¬åœ°GPU(å¤§äº40Gæ˜¾å­˜)ç›´æ¥è°ƒè¯•ï¼ï¼‰
- 20250224ï¼šğŸ¯feat(quickllm/base_rope.py):æ–°å¢ROPEç®€æ˜“è°ƒè¯•ä»£ç 
- 20250220ï¼šğŸ¯feat(learnings/MLA/*):æ–°å¢deepseek-MLAæ³¨æ„åŠ›æœºåˆ¶è°ƒè¯•ä»£ç 
- 20250220ï¼šğŸ¯feat(learnings/tiny_grpo/*):æ–°å¢deepseek-grpoè°ƒè¯•ä»£ç 
- 20231225ï¼šğŸ¯feat(basic_llm_moe_transformers.py):æ–°å¢transformersåŒ…çš„Mixtral-8x7B/MOEæºä»£ç è°ƒè¯•

## äºŒã€GRPOç›¸å…³å·¥ä½œ

ä»£ç ï¼š**learnings/tiny-grpo/***

å¥–åŠ±å’Œlossæ›²çº¿ï¼š

![img.png](docs/img.png)

### 2.1 æ ¸å¿ƒè®­ç»ƒæµç¨‹

#### 2.1.1 Rollouté˜¶æ®µ
```python
def rollout(model, tokenizer, task, oracle_answer, num_rollouts=12):
    # 1. æ„å»ºæç¤ºè¯
    chat_prompt = tokenizer.apply_chat_template(chat_messages, ...)
    
    # 2. ç”Ÿæˆå¤šä¸ªå€™é€‰ç­”æ¡ˆ
    sequence_ids = model.generate(
        input_ids=model_inputs["input_ids"],
        generation_config=generation_config
    )
    
    # 3. è®¡ç®—ç›¸å¯¹å¥–åŠ±
    for i, completion in enumerate(completions):
        answer_match = re.search(r"<answer>(.*?)</answer>", completion)
        if answer_match:
            answer = answer_match.group(1)
            if answer == oracle_answer:
                reward = 1.0      # å®Œå…¨æ­£ç¡®
            elif oracle_answer in answer:
                reward = 0.5      # éƒ¨åˆ†æ­£ç¡®
            else:
                reward = 0.01     # é”™è¯¯
```

#### 2.1.2 ä¼˜åŠ¿è®¡ç®—
```python
# å¯¹ç»„å†…å¥–åŠ±è¿›è¡Œæ ‡å‡†åŒ–
advantages = group_advantages(returns)
# advantages = (returns - returns.mean()) / (returns.std() + eps)
```

#### 2.1.3 æŸå¤±è®¡ç®—
```python
class GRPOLoss(nn.Module):
    def forward(self, log_probs, experience):
        # PPOè£å‰ªæŸå¤±
        ratio = (log_probs - old_log_probs).exp()
        surr1 = ratio * advantages
        surr2 = ratio.clamp(1 - clip_eps, 1 + clip_eps) * advantages
        ppo_loss = -torch.min(surr1, surr2)
        
        # KLæ•£åº¦çº¦æŸ
        kl = approx_kl_divergence(log_probs, log_probs_ref, action_mask)
        
        # æ€»æŸå¤±
        total_loss = ppo_loss + kl_weight * kl
        return total_loss, kl.mean()
```

## ä¸‰. é¢„è®­ç»ƒæƒé‡
- è‹¥æ— è¯´æ˜åˆ™ä½¿ç”¨[huggingfaceå®˜ç½‘](https://huggingface.co/models)ä¸­å¯¹åº”æ¨¡å‹çš„`pytorch_model.bin`å’Œå¯¹åº”config.json


## å››.é¸£è°¢

- æ„Ÿè°¢Tongjiliboçš„[bert4torch](https://github.com/Tongjilibo/bert4torch)ï¼Œæœ¬å®ç°é‡ç‚¹å‚è€ƒäº†è¿™ä¸ªé¡¹ç›®ï¼Œè¿›è¡Œäº†ä¼˜åŒ–å’Œæ›´æ–°ï¼›é¡¹ç›®ä¼šæŒç»­è·Ÿè¿›bert4torchçš„æœ€æ–°å®ç°

- æ„Ÿè°¢è‹ç¥å®ç°çš„[bert4keras](https://github.com/bojone/bert4keras)ï¼Œæœ‰äº›åœ°æ–¹å‚è€ƒäº†bert4kerasçš„æºç ï¼Œåœ¨æ­¤è¡·å¿ƒæ„Ÿè°¢å¤§ä½¬çš„æ— ç§å¥‰çŒ®ï¼›å¤§ä½¬çš„ç§‘å­¦ç©ºé—´

  ```bibtex
  @misc{bert4torch,
    title={bert4torch},
    author={Bo Li},
    year={2022},
    howpublished={\url{https://github.com/Tongjilibo/bert4torch}},
  }
  ```

## äº”. å¼•ç”¨

```bibtex
@misc{quickllm,
  title={quickllm},
  author={NLPå°è®²å ‚},
  year={2022},
  howpublished={\url{https://github.com/zysNLP/quickllm}},
}
```

![star-history-2025526](https://github.com/user-attachments/assets/4832ba81-14d0-413b-9036-345585c76ab2)


## å…­. å…¶ä»–

å…³æ³¨å…¬ä¼—å·ã€ŠNLPå°è®²å ‚ã€‹ï¼Œæ›´å¤šé«˜æ•ˆå†…å®¹åŠæ—¶è®¢é˜…ï¼Œæœ€æ–°æ–‡ç« å’Œ[è§†é¢‘](https://edu.csdn.net/course/detail/39082)åŒæ­¥ï¼Œ[Bç«™å…³æ³¨](https://www.bilibili.com/video/BV1hG411e7Ng/?spm_id_from=333.999.0.0&vd_source=9a2f107418c10b543b13cbd8e1f9e98d)ï¼š

ã€ŠMixtral-8x7B-Instruct-v0.1çš„finetuneå¾®è°ƒå®æˆ˜ã€‹ï¼šå‚è€ƒå€Ÿé‰´[Aurora](https://github.com/WangRongsheng/Aurora)ï¼Œ[Firefly](https://github.com/yangjianxin1/Firefly)

[ã€Šæµ…è°ˆMOEçš„ä»£ç åŸç†ï¼ˆä¸€ï¼‰ï¼Œæ˜¯å¦è¶³å¤Ÿå¯¹æ ‡self-attentionï¼Ÿã€‹](https://mp.weixin.qq.com/s/mbXePBZXIiN3aa8sszPzHQ)å‚è€ƒå€Ÿé‰´ï¼š[Mistral Transformers](https://github.com/mistralai/mistral-src)ï¼Œ[Mixture of Expert](https://github.com/lucidrains/mixture-of-experts.git)

ã€ŠTritonå¤æ‚åˆç®€å•ï¼šæŠŠéƒ¨ç½²åˆ‡æˆåšåšçš„è–„ç‰‡ã€‚ã€‚ã€‹å‚è€ƒå€Ÿé‰´ï¼š[NGC Tritoné•œåƒ](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver)ï¼Œ[Triton Inference Server GitHubå®˜ç½‘](https://github.com/triton-inference-server/server)

ã€ŠTensorRT-LLMï¼šå¤§æ¨¡å‹æ¨ç†åŠ é€Ÿå¿…å¤‡ã€‹å‚è€ƒå€Ÿé‰´ï¼š[Qwen-TensorRTåŸç†](https://developer.nvidia.com/zh-cn/blog/qwen-model-support-nvidia-tensorrt-llm)ï¼Œ[Qwen-TensorRTä»£ç ](https://github.com/Tlntin/Qwen-TensorRT-LLM/tree/main?tab=readme-ov-file)

ã€ŠLORAè®ºæ–‡è§£è¯»ï¼šå¤§æ¨¡å‹çš„ä½ç§©é€‚åº”ã€‹å‚è€ƒå€Ÿé‰´ï¼š[LORAè®ºæ–‡](https://arxiv.org/pdf/2106.09685.pdf)ï¼Œ[LORAè®ºæ–‡è§£è¯»](https://zhuanlan.zhihu.com/p/624576869)
